{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling Rating and Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PACKAGES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from fuzzywuzzy import fuzz\n",
    "import textdistance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CODE PARAMETERS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PANDAS DISPLAY PARAMETERS\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "# pd.set_option('display.width', None)\n",
    "# pd.set_option('display.max_colwidth', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_ratings_path = r'../data/clean_data/'\n",
    "input_rating_paths = os.path.join(os.getcwd(),r'../data/raw_data/Rating and Reviews/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_product_path = r'../data/clean_data/'\n",
    "input_product_paths = os.path.join(os.getcwd(),r'../data/raw_data/Product Catalogue/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_demand_paths = os.path.join(os.getcwd(),r'../data/raw_data/Demand Data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregating Product Catalogue Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a look at the available data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(input_product_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a DataFrame for skincare and cosmetics that concatenates all the dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_skincare = pd.DataFrame()\n",
    "product_cosmetics = pd.DataFrame()\n",
    "for file in os.listdir(input_product_paths):\n",
    "    if '.csv' in file.lower():\n",
    "        if 'skincare' in file.lower():\n",
    "            print('Adding', file)\n",
    "            temp = pd.read_csv(os.path.join(input_product_paths,file))\n",
    "            temp = temp.loc[:, ~temp.columns.str.contains('^Unnamed')]\n",
    "            product_skincare=pd.concat([product_skincare, temp])\n",
    "        elif 'cosmetics' in file.lower():\n",
    "            print('Adding', file)\n",
    "            temp = pd.read_csv(os.path.join(input_product_paths,file))\n",
    "            temp = temp.loc[:, ~temp.columns.str.contains('^Unnamed')]\n",
    "            product_cosmetics=pd.concat([product_cosmetics, temp])\n",
    "del temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skincare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by changing the columns names to make them code friendly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_skincare.columns = [colname.lower().replace(' ','_') for colname in product_skincare.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We format the Clean Collection Date and fill the missing rows/bad format with the oldest date available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_skincare['clean_collection_date'] = pd.to_datetime(product_skincare['collection_date'], errors='coerce')\n",
    "product_skincare.loc[product_skincare['clean_collection_date'].isna(), 'collection_date']=min(product_skincare['clean_collection_date'])\n",
    "product_skincare['clean_collection_date'] = pd.to_datetime(product_skincare['collection_date'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We drop the duplicates while only keeping the row with the most recent Collection Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_skincare = product_skincare.sort_values('clean_collection_date', ascending=False).dropna(subset=['brand']).drop_duplicates([\n",
    "    'elc_solution_type',\n",
    "    'source_product_identifier', \n",
    "    'product_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we save the DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_skincare.to_csv(os.path.join(output_product_path,'product_catalogue_skincare.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosmetics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do the same for Coemetics. We start by changing the columns names to make them code friendly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_cosmetics.columns = [colname.lower().replace(' ','_') for colname in product_cosmetics.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We format the Clean Collection Date and fill the missing rows/bad format with the oldest date available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_cosmetics['clean_collection_date'] = pd.to_datetime(product_cosmetics['collection_date'], errors='coerce')\n",
    "product_cosmetics.loc[product_cosmetics['clean_collection_date'].isna(), 'collection_date']=min(product_cosmetics['clean_collection_date'])\n",
    "product_cosmetics['clean_collection_date'] = pd.to_datetime(product_cosmetics['collection_date'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We drop the duplicates while only keeping the row with the most recent Collection Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_cosmetics.sort_values('clean_collection_date', ascending=False).dropna(subset=['brand']).drop_duplicates([\n",
    "    'elc_solution_type',\n",
    "    'source_product_identifier', \n",
    "    'product_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we save the DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_cosmetics.to_csv(os.path.join(output_product_path,'product_catalogue_cosmetics.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregating Ratings and Reviews Data\n",
    "1. Filter only on US\n",
    "2. create data by YM\n",
    "3. change sentiment to num_sentiment : -1,0,1\n",
    "4. change sentiments to hot ones HO_sentiment\n",
    "5. create hot ones rating\n",
    "5. Groupby YM, Source Product Identifierm, Channel, Product_ID\n",
    "6. Aggregate by {num_sentiment:mean, num_rating:mean, HO_sentiments:count, HO_rating:count}\n",
    "7. Number of reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_rating_and_reviews(df, product_catalogue):\n",
    "    print('Formatting data...')\n",
    "    df.columns = [colname.lower().replace(' ','_') for colname in df.columns]\n",
    "    df = df[df['geography']=='USA']\n",
    "    df.loc[:,'clean_date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "    df.loc[:,'year'] = df.loc[:,'clean_date'].dt.year\n",
    "    df.loc[:,'month'] = df.loc[:,'clean_date'].dt.month\n",
    "    df.loc[:,'rating'] = df['rating'].fillna(-1).astype(int)\n",
    "    df.loc[:,'sentiment'] = df['sentiment'].str.lower()\n",
    "    df = pd.concat([df, pd.get_dummies(data=df[['rating','sentiment']], columns=['rating','sentiment'], dtype=int)], axis=1)\n",
    "    df.loc[:,'sentiment'] = df['sentiment_positive'] - df['sentiment_negative']\n",
    "    df.loc[df['rating']==-1,'rating'] = np.nan\n",
    "    df.loc[:,'nb_ratings'] = df['rating']\n",
    "    \n",
    "    # We could add 'elc_solution_type' and 'channel' to groupby !\n",
    "    print('Aggregating data...')\n",
    "    df = df.groupby(['elc_solution_type',\n",
    "                     'source_product_identifier', \n",
    "                     'product_id', \n",
    "                     'year', \n",
    "                     'month']).agg({\n",
    "        'nb_ratings':'count',\n",
    "        'rating':'mean',\n",
    "        'rating_1':'sum',\n",
    "        'rating_2':'sum',\n",
    "        'rating_3':'sum',\n",
    "        'rating_4':'sum',\n",
    "        'rating_5':'sum',\n",
    "        'sentiment_negative':'sum',\n",
    "        'sentiment_neutral':'sum',\n",
    "        'sentiment_positive':'sum',\n",
    "        'sentiment':'mean'\n",
    "    }).reset_index()\n",
    "    print('Adding product catalogue data...')\n",
    "    initial_size=len(df)\n",
    "    product_catalogue = product_catalogue[['elc_solution_type',\n",
    "                                           'source_product_identifier', \n",
    "                                           'product_id',\n",
    "                                           'brand']].drop_duplicates(['elc_solution_type',\n",
    "                                                                      'source_product_identifier', \n",
    "                                                                      'product_id'])\n",
    "    df = df.merge(product_catalogue[['elc_solution_type','source_product_identifier', 'product_id', 'brand']], how='left')\n",
    "    df['brand'].fillna(df.merge(product_catalogue[['elc_solution_type','source_product_identifier','brand']].drop_duplicates(), on=['elc_solution_type','source_product_identifier'], how='left', suffixes=['','_filler'])['brand_filler'], inplace=True)\n",
    "    df['brand'].fillna(df.merge(product_catalogue[['source_product_identifier','brand']].drop_duplicates(), on=['source_product_identifier'], how='left', suffixes=['','_filler'])['brand_filler'], inplace=True)\n",
    "    print('Check that no duplicates have been created:', initial_size==len(df))\n",
    "    if df.isna().sum().sum()>0:\n",
    "        print('Missing values:')\n",
    "        display(df.isna().sum()/len(df)*100)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "types = {'OnlinePost_ID': object,\n",
    " 'Source Product Identifier': object,\n",
    " 'OnlineStatement_ID': object,\n",
    " 'Date': object,\n",
    " 'Title': object,\n",
    " 'Description': object,\n",
    " 'Geography': object,\n",
    " 'Channel': object,\n",
    " 'Product_ID': object,\n",
    " 'Rating': float,\n",
    " 'Sentiment': object,\n",
    " 'Feature': object,\n",
    " 'Benefit': object,\n",
    " 'Ingredient': object,\n",
    " 'Additional Ingredients (no rulebase)': object,\n",
    " 'Product Form': object,\n",
    " 'ELC Solution Type': object,\n",
    " 'Finish': object,\n",
    " 'Looks': object,\n",
    " 'Other': object,\n",
    " 'Trends': object,\n",
    " 'Syndication Source': object,\n",
    " 'Best For': object,\n",
    " 'Verified Buyer': object,\n",
    " 'From': object,\n",
    " 'Recommended': object,\n",
    " 'Verified Reviewer': object,\n",
    " 'Eye Color': object,\n",
    " 'Hair Color': object,\n",
    " 'Skin Tone': object,\n",
    " 'Gender': object,\n",
    " 'I shop at macys.com': object,\n",
    " 'Make-up Style': object,\n",
    " 'Purchase Location': object,\n",
    " 'Cons': object,\n",
    " 'Pros': object,\n",
    " 'Describe Yourself': object,\n",
    " 'Reviewer Skin Type': object,\n",
    " 'Age': object}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(input_rating_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_files_to_read_skincare = 0\n",
    "nb_files_to_read_cosmetics = 0\n",
    "for file in os.listdir(input_rating_paths):\n",
    "    if '.csv' in file.lower() :\n",
    "        if 'skincare' in file.lower():\n",
    "            nb_files_to_read_skincare+=1\n",
    "        elif 'cosmetics' in file.lower():\n",
    "            nb_files_to_read_cosmetics+=1\n",
    "print('Number of skincare files to read:', nb_files_to_read_skincare)\n",
    "print('Number of cosmetics files to read:', nb_files_to_read_cosmetics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Skincare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_skincare = pd.read_csv(os.path.join(output_product_path,'product_catalogue_skincare.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "nb_read_skincare = 0\n",
    "ratings_skincare = pd.DataFrame()\n",
    "   \n",
    "for file in os.listdir(input_rating_paths):\n",
    "    if '.csv' in file.lower() and 'skincare' in file.lower():\n",
    "        interm = time.time()\n",
    "        nb_read_skincare+=1\n",
    "        print('Reading', file, nb_read_skincare,'out of', nb_files_to_read_skincare, '...')\n",
    "        temp = pd.read_csv(os.path.join(input_rating_paths,file))\n",
    "        temp = temp.loc[:, ~temp.columns.str.contains('^Unnamed')]\n",
    "        temp = format_rating_and_reviews(temp, product_skincare)\n",
    "        ratings_skincare = pd.concat([ratings_skincare, temp])\n",
    "        print('New length skincare:', len(ratings_skincare))\n",
    "        print('Time for this dataset:', time.time()-interm)\n",
    "        print('Total time:', time.time()-start)\n",
    "del temp\n",
    "ratings_skincare.to_csv(os.path.join(output_ratings_path,'ratings_and_reviews_skincare_by_product_id.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cosmetics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_cosmetics = pd.read_csv(os.path.join(output_product_path,'product_catalogue_cosmetics.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "nb_read_cosmetics = 0\n",
    "ratings_cosmetics = pd.DataFrame()\n",
    "for file in os.listdir(input_rating_paths):\n",
    "    if '.csv' in file.lower() and 'cosmetics' in file.lower():\n",
    "        interm = time.time()\n",
    "        nb_read_cosmetics+=1\n",
    "        print('Reading', file, nb_read_cosmetics,'out of', nb_files_to_read_cosmetics, '...')\n",
    "        temp = pd.read_csv(os.path.join(input_rating_paths,file))\n",
    "        temp = temp.loc[:, ~temp.columns.str.contains('^Unnamed')]\n",
    "        temp = format_rating_and_reviews(temp, product_cosmetics)\n",
    "        ratings_cosmetics = pd.concat([ratings_cosmetics, temp])\n",
    "        print('New length cosmetic:', len(ratings_cosmetics))\n",
    "        print('Time for this dataset:', time.time()-interm)\n",
    "        print('Total time:', time.time()-start)\n",
    "del temp\n",
    "ratings_cosmetics.to_csv(os.path.join(output_ratings_path,'ratings_and_reviews_cosmetics_by_product_id.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging  Skincare and Cosmetics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_skincare['major_category'] = 'Skincare'\n",
    "ratings_cosmetics['major_category'] = 'Cosmetics'\n",
    "ratings = pd.concat([ratings_skincare, ratings_cosmetics])\n",
    "ratings['brand'] = ratings['brand'].str.lower()\n",
    "ratings.to_csv(os.path.join(output_ratings_path,'ratings_and_reviews_by_product_id.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping Brands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elc_brands = pd.read_csv('../data/clean_data/elc_brands.csv', encoding = \"ISO-8859-1\")\n",
    "elc_brands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brands = pd.DataFrame({'brand' : ratings['brand'].unique()})\n",
    "brands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_matching = brands.assign(key=0).merge(elc_brands.assign(key=0), on='key', how='left').drop('key', axis=1)\n",
    "brand_matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_distance(row):\n",
    "    jaro = textdistance.jaro_winkler(str(row['brand']).lower().replace('.','').replace('&','and'), str(row['elc_brand']).lower().replace('.',''))\n",
    "#     jaccard = textdistance.jaccard(str(row['brand']).lower().replace('.','').replace('&','and'), str(row['elc_brand']).lower().replace('.',''))\n",
    "    fuzzi = fuzz.partial_ratio(str(row['brand']).lower().replace('.','').replace('&','and'), str(row['elc_brand']).lower().replace('.',''))/100\n",
    "    return (fuzzi+jaro)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_matching['score'] = brand_matching.apply(lambda row : custom_distance(row), axis=1)\n",
    "brand_matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_matching.to_csv('../data/clean_data/brand_mapping_scores.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_matching = brand_matching.groupby('brand').apply(lambda x: x.nlargest(1,'score')).reset_index(drop=True)\n",
    "brand_matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_matching.loc[brand_matching['score']>0.92]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_matching.loc[brand_matching['score']<0.92, 'brand_abbrev'] = np.nan\n",
    "brand_matching.loc[brand_matching['score']<0.92, 'elc_brand'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_matching.drop('score', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', len(brand_matching)+1)\n",
    "display(brand_matching)\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_matching.to_csv('../data/clean_data/brand_mapping.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate by Brand - ELC solution type - year - month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = ratings.merge(brand_matching, how='left', on='brand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.dropna(subset=['elc_brand'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = ratings.groupby(['elc_brand',\n",
    "                           'brand_abbrev',\n",
    "                           'elc_solution_type', \n",
    "                           'year',\n",
    "                           'month']).agg({\n",
    "        'rating_1':'sum',\n",
    "        'rating_2':'sum',\n",
    "        'rating_3':'sum',\n",
    "        'rating_4':'sum',\n",
    "        'rating_5':'sum',\n",
    "        'sentiment_negative':'sum',\n",
    "        'sentiment_neutral':'sum',\n",
    "        'sentiment_positive':'sum',\n",
    "    }).reset_index().rename(columns={\n",
    "    'brand_abbrev':'brand',\n",
    "    'elc_solution_type':'sub_category'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings['date'] = pd.to_datetime(ratings[['year', 'month']].assign(DAY=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.drop(['year', 'month'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formating Demand Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demand = pd.read_csv(os.path.join(input_demand_paths,'NA+UK demand data by category FY17-FY20.csv'))\n",
    "demand.columns = [col.lower().replace(' ','_') for col in demand.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_columns = demand.columns[demand.columns.str.contains('/')].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demand[demand == '-']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demand.loc[:, dates_columns] = demand.loc[:, dates_columns].apply(lambda x: x.str.replace(',', '').fillna(0).astype(int), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demand = demand.groupby(['brand', 'sub_category'])[dates_columns].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demand.columns.name = 'date'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demand = demand.stack().to_frame('demand').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demand['date'] = pd.to_datetime(demand['date'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_demand = ratings.merge(demand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_demand.to_csv('../data/clean_data/ratings_with_demand.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXTRA CODE\n",
    "Bad idea, since some of the files are bigger than 5 Gb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skincare = pd.DataFrame()\n",
    "# cosmetic = pd.DataFrame()\n",
    "# for file in listdir(path):\n",
    "#     if '.csv' in file.lower():\n",
    "#         if 'skincare' in file.lower():\n",
    "#             print('Adding', file)\n",
    "#             skincare=pd.concat([skincare, pd.read_csv(os.path.join(path,file))])\n",
    "#             display(skincare)\n",
    "#         elif 'cosmetics' in file.lower():\n",
    "#             print('Adding', file)\n",
    "#             cosmetic=pd.concat([cosmetic, pd.read_csv(os.path.join(path,file))])\n",
    "#             display(cosmetic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skincare = dict()\n",
    "# cosmetic = dict()\n",
    "# for file in listdir(path):\n",
    "#     if '.csv' in file.lower():\n",
    "#         if 'skincare' in file.lower():\n",
    "#             print('Adding', file)\n",
    "#             skincare[file] = pd.read_csv(os.path.join(path,file))\n",
    "# #         elif 'cosmetics' in file.lower():\n",
    "# #             print('Adding', file)\n",
    "# #             cosmetic[file] = pd.read_csv(os.path.join(path,file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(cosmetic, open( \"../data/Rating and Reviews/cosmetic.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cosmetic_df=pd.DataFrame()\n",
    "# for key, df in cosmetic.items():\n",
    "#     print(key)\n",
    "#     print(df.columns)\n",
    "#     example=df\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# product_skincare[product_skincare[[\n",
    "#     'elc_solution_type',\n",
    "#     'source_product_identifier', \n",
    "#     'product_id']].duplicated(keep=False)][[\n",
    "#     'elc_solution_type',\n",
    "#     'source_product_identifier', \n",
    "#     'product_id',\n",
    "#     'brand']].sort_values([\n",
    "#     'elc_solution_type',\n",
    "#     'source_product_identifier', \n",
    "#     'product_id',\n",
    "#     'brand'])['brand'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nb_files_to_read = 0\n",
    "# for file in os.listdir(ratings_input_product_paths):\n",
    "#     if ('.csv' in file.lower()) and (('skincare' in file.lower()) or ('cosmetics' in file.lower())):\n",
    "#         nb_files_to_read+=1\n",
    "# nb_files_to_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# start = time.time()\n",
    "# nb_read = 0\n",
    "# ratings_skincare = pd.DataFrame()\n",
    "# ratings_cosmetics = pd.DataFrame()\n",
    "# for file in os.listdir(ratings_input_product_paths):\n",
    "#     if '.csv' in file.lower():\n",
    "#         if 'skincare' in file.lower():\n",
    "#             interm = time.time()\n",
    "#             nb_read+=1\n",
    "#             print('Reading', file, nb_read,'out of', nb_files_to_read, '...')\n",
    "#             temp = pd.read_csv(os.path.join(ratings_input_product_paths,file))\n",
    "#             temp = temp.loc[:, ~temp.columns.str.contains('^Unnamed')]\n",
    "#             temp = format_rating_and_reviews(temp, product_skincare)\n",
    "#             ratings_skincare = pd.concat([ratings_skincare, temp])\n",
    "#             print('New length skincare:', len(ratings_skincare))\n",
    "#             print('Time for this dataset:', time.time()-interm)\n",
    "#             print('Total time:', time.time()-start)\n",
    "#         elif 'cosmetics' in file.lower():\n",
    "#             interm = time.time()\n",
    "#             nb_read+=1\n",
    "#             print('Reading', file, nb_read,'out of', nb_files_to_read, '...')\n",
    "#             temp = pd.read_csv(os.path.join(ratings_input_product_paths,file))\n",
    "#             temp = temp.loc[:, ~temp.columns.str.contains('^Unnamed')]\n",
    "#             temp = format_rating_and_reviews(temp, product_cosmetics)\n",
    "#             ratings_cosmetics = pd.concat([ratings_cosmetics, temp])\n",
    "#             print('New length cosmetic:', len(ratings_cosmetics))\n",
    "#             print('Time for this dataset:', time.time()-interm)\n",
    "#             print('Total time:', time.time()-start)\n",
    "# del temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratings_cosmetics.to_csv(os.path.join(output_ratings_path,'ratings_and_reviews_cosmetics.csv'), index=False)\n",
    "# ratings_skincare.to_csv(os.path.join(output_ratings_path,'ratings_and_reviews_skincare.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "398px",
    "left": "132px",
    "top": "110px",
    "width": "183.53px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
