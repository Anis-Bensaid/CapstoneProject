{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling using LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # To be run only once\n",
    "# if 0 == 1:\n",
    "#     !pip install gensim\n",
    "#     !pip install PyLDAvis\n",
    "#     !pip install spacy\n",
    "#     !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "import spacy\n",
    "import tqdm\n",
    "\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "import gensim.corpora as corpora\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import en_core_web_sm\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "import pyLDAvis.gensim\n",
    "import pickle \n",
    "import pyLDAvis\n",
    "\n",
    "import time\n",
    "from collections import Counter\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cache stop_words into hash\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from'])\n",
    "stop_words = Counter(stop_words)\n",
    "\n",
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=['parser', 'ner'])\n",
    "\n",
    "random.seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one_drive_path = \"C:/Users/cfowle/The Estée Lauder Companies Inc/TeamAnis - General/\"\n",
    "one_drive_path = \"C:/Users/asaid/The Estée Lauder Companies Inc/TeamAnis - General/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('reviews.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['geography']=='USA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['onlinepost_id', 'source_product_identifier', 'onlinestatement_id',\n",
    "       'date', 'title', 'description', 'geography', 'channel', 'product_id',\n",
    "       'rating', 'sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asaid\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3997: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "df.drop(columns=['geography'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>onlinepost_id</th>\n",
       "      <th>source_product_identifier</th>\n",
       "      <th>onlinestatement_id</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>channel</th>\n",
       "      <th>product_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OnlinePost_20191027_184110681</td>\n",
       "      <td>pimprod2006667</td>\n",
       "      <td>OnlineStatement_20191027_184110681_5</td>\n",
       "      <td>2019-09-06</td>\n",
       "      <td>Nice!</td>\n",
       "      <td>I am very pleased!</td>\n",
       "      <td>Ulta</td>\n",
       "      <td>Product_20191016_5443258</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OnlinePost_20191027_184748557</td>\n",
       "      <td>pimprod2006667</td>\n",
       "      <td>OnlineStatement_20191027_184748557_5</td>\n",
       "      <td>2019-09-07</td>\n",
       "      <td>. I would recommended if in budget.</td>\n",
       "      <td>However I wish it got rid of the powdery look ...</td>\n",
       "      <td>Ulta</td>\n",
       "      <td>Product_20191016_5443258</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OnlinePost_20191027_184112758</td>\n",
       "      <td>pimprod2006667</td>\n",
       "      <td>OnlineStatement_20191027_184112758_1</td>\n",
       "      <td>2019-09-13</td>\n",
       "      <td>Love it!</td>\n",
       "      <td>Love it!</td>\n",
       "      <td>Ulta</td>\n",
       "      <td>Product_20191016_5443258</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OnlinePost_20191027_183920306</td>\n",
       "      <td>pimprod2006667</td>\n",
       "      <td>OnlineStatement_20191027_183920306_4</td>\n",
       "      <td>2019-09-27</td>\n",
       "      <td>Perfect Product!</td>\n",
       "      <td>It helps my makeup lady all day!</td>\n",
       "      <td>Ulta</td>\n",
       "      <td>Product_20191016_5443258</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OnlinePost_20191027_184386195</td>\n",
       "      <td>pimprod2006667</td>\n",
       "      <td>OnlineStatement_20191027_184386195_1</td>\n",
       "      <td>2019-09-19</td>\n",
       "      <td>AmaIng!</td>\n",
       "      <td>AmaIng!</td>\n",
       "      <td>Ulta</td>\n",
       "      <td>Product_20191016_5443258</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20129659</th>\n",
       "      <td>OnlinePost_20200524_6edee6cd-4283-497c-b37f-94...</td>\n",
       "      <td>10486034</td>\n",
       "      <td>OnlineStatement_20200524_6edee6cd-4283-497c-b3...</td>\n",
       "      <td>2020-04-10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Within two days I noticed how much better my s...</td>\n",
       "      <td>Macy's</td>\n",
       "      <td>Product_20200416_18804683</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20129660</th>\n",
       "      <td>OnlinePost_20200524_1c5b762d-bd4f-4935-8559-be...</td>\n",
       "      <td>2717198</td>\n",
       "      <td>OnlineStatement_20200524_1c5b762d-bd4f-4935-85...</td>\n",
       "      <td>2020-04-09</td>\n",
       "      <td>Ok</td>\n",
       "      <td>It's a very thick cream, which I don't usually...</td>\n",
       "      <td>Bloomingdales</td>\n",
       "      <td>Product_20200416_18796718</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20129662</th>\n",
       "      <td>OnlinePost_20200524_38ab5dd5-5c1d-4b7f-b2e3-6e...</td>\n",
       "      <td>3438423</td>\n",
       "      <td>OnlineStatement_20200524_38ab5dd5-5c1d-4b7f-b2...</td>\n",
       "      <td>2020-04-18</td>\n",
       "      <td>Great Product</td>\n",
       "      <td>Great Product.</td>\n",
       "      <td>Bloomingdales</td>\n",
       "      <td>Product_20200416_18799806</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20129663</th>\n",
       "      <td>OnlinePost_20200524_a21bc2f7-d2b2-4660-bd9a-07...</td>\n",
       "      <td>4900069</td>\n",
       "      <td>OnlineStatement_20200524_a21bc2f7-d2b2-4660-bd...</td>\n",
       "      <td>2020-04-08</td>\n",
       "      <td>Amazingly subtle colour and radiance</td>\n",
       "      <td>So easy to use and love the fact I can still u...</td>\n",
       "      <td>Nordstrom</td>\n",
       "      <td>Product_20200416_18822798</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20129665</th>\n",
       "      <td>OnlinePost_20200524_62128828-0fed-4da9-bd66-a0...</td>\n",
       "      <td>5059239</td>\n",
       "      <td>OnlineStatement_20200524_62128828-0fed-4da9-bd...</td>\n",
       "      <td>2020-04-14</td>\n",
       "      <td>LOVE THESE.</td>\n",
       "      <td>I use them every morning (worried it would be ...</td>\n",
       "      <td>Nordstrom</td>\n",
       "      <td>Product_20200416_18822287</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18002990 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              onlinepost_id  \\\n",
       "0                             OnlinePost_20191027_184110681   \n",
       "1                             OnlinePost_20191027_184748557   \n",
       "2                             OnlinePost_20191027_184112758   \n",
       "3                             OnlinePost_20191027_183920306   \n",
       "4                             OnlinePost_20191027_184386195   \n",
       "...                                                     ...   \n",
       "20129659  OnlinePost_20200524_6edee6cd-4283-497c-b37f-94...   \n",
       "20129660  OnlinePost_20200524_1c5b762d-bd4f-4935-8559-be...   \n",
       "20129662  OnlinePost_20200524_38ab5dd5-5c1d-4b7f-b2e3-6e...   \n",
       "20129663  OnlinePost_20200524_a21bc2f7-d2b2-4660-bd9a-07...   \n",
       "20129665  OnlinePost_20200524_62128828-0fed-4da9-bd66-a0...   \n",
       "\n",
       "         source_product_identifier  \\\n",
       "0                   pimprod2006667   \n",
       "1                   pimprod2006667   \n",
       "2                   pimprod2006667   \n",
       "3                   pimprod2006667   \n",
       "4                   pimprod2006667   \n",
       "...                            ...   \n",
       "20129659                  10486034   \n",
       "20129660                   2717198   \n",
       "20129662                   3438423   \n",
       "20129663                   4900069   \n",
       "20129665                   5059239   \n",
       "\n",
       "                                         onlinestatement_id        date  \\\n",
       "0                      OnlineStatement_20191027_184110681_5  2019-09-06   \n",
       "1                      OnlineStatement_20191027_184748557_5  2019-09-07   \n",
       "2                      OnlineStatement_20191027_184112758_1  2019-09-13   \n",
       "3                      OnlineStatement_20191027_183920306_4  2019-09-27   \n",
       "4                      OnlineStatement_20191027_184386195_1  2019-09-19   \n",
       "...                                                     ...         ...   \n",
       "20129659  OnlineStatement_20200524_6edee6cd-4283-497c-b3...  2020-04-10   \n",
       "20129660  OnlineStatement_20200524_1c5b762d-bd4f-4935-85...  2020-04-09   \n",
       "20129662  OnlineStatement_20200524_38ab5dd5-5c1d-4b7f-b2...  2020-04-18   \n",
       "20129663  OnlineStatement_20200524_a21bc2f7-d2b2-4660-bd...  2020-04-08   \n",
       "20129665  OnlineStatement_20200524_62128828-0fed-4da9-bd...  2020-04-14   \n",
       "\n",
       "                                         title  \\\n",
       "0                                        Nice!   \n",
       "1          . I would recommended if in budget.   \n",
       "2                                     Love it!   \n",
       "3                             Perfect Product!   \n",
       "4                                      AmaIng!   \n",
       "...                                        ...   \n",
       "20129659                                   NaN   \n",
       "20129660                                    Ok   \n",
       "20129662                         Great Product   \n",
       "20129663  Amazingly subtle colour and radiance   \n",
       "20129665                           LOVE THESE.   \n",
       "\n",
       "                                                description        channel  \\\n",
       "0                                        I am very pleased!           Ulta   \n",
       "1         However I wish it got rid of the powdery look ...           Ulta   \n",
       "2                                                  Love it!           Ulta   \n",
       "3                          It helps my makeup lady all day!           Ulta   \n",
       "4                                                   AmaIng!           Ulta   \n",
       "...                                                     ...            ...   \n",
       "20129659  Within two days I noticed how much better my s...         Macy's   \n",
       "20129660  It's a very thick cream, which I don't usually...  Bloomingdales   \n",
       "20129662                                     Great Product.  Bloomingdales   \n",
       "20129663  So easy to use and love the fact I can still u...      Nordstrom   \n",
       "20129665  I use them every morning (worried it would be ...      Nordstrom   \n",
       "\n",
       "                         product_id  rating sentiment  \n",
       "0          Product_20191016_5443258     4.0  Positive  \n",
       "1          Product_20191016_5443258     4.0  Positive  \n",
       "2          Product_20191016_5443258     5.0  Positive  \n",
       "3          Product_20191016_5443258     5.0  Positive  \n",
       "4          Product_20191016_5443258     5.0   Neutral  \n",
       "...                             ...     ...       ...  \n",
       "20129659  Product_20200416_18804683     5.0  Positive  \n",
       "20129660  Product_20200416_18796718     3.0  Positive  \n",
       "20129662  Product_20200416_18799806     5.0  Positive  \n",
       "20129663  Product_20200416_18822798     5.0  Positive  \n",
       "20129665  Product_20200416_18822287     5.0  Positive  \n",
       "\n",
       "[18002990 rows x 10 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_pickle('reviews_columns.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.sample(100, random_state=3)\n",
    "# del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cache stop_words into hash\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from'])\n",
    "stop_words = Counter(stop_words)\n",
    "\n",
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=['parser', 'ner'])\n",
    "\n",
    "def preprocess(sentences, stop_words, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    # lower case\n",
    "    # Remove stop words\n",
    "    # Lemmatize\n",
    "    for sentence in sentences:\n",
    "        doc = nlp(' '.join([token for token in gensim.utils.simple_preprocess(str(sentence), deacc=True) if token not in stop_words]) )\n",
    "        yield([token.lemma_ for token in doc if token.pos_ in allowed_postags])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = list(tqdm.tqdm(preprocess(df.values.tolist(), stop_words), position=0, leave=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = pickle.load(open(\"docs.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = corpora.Dictionary(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = pd.DataFrame(d.dfs.values(), index=d.dfs.keys(), columns=['freq'])\n",
    "freq.index.name = 'idx'\n",
    "freq = freq.reset_index()\n",
    "freq['token'] = freq['idx'].apply(lambda x:d[x])\n",
    "freq = freq.sort_values(by='freq', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.token2id['transition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.dfs[115]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq.iloc[0:50].plot.bar(x='token', y='freq', figsize=(20,20))\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(d.dfs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.id2token[112]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, freq in d.dfs.items():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(d.dfs, index=d.dfs.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs\n",
    "docs = random.sample(docs, 100000)\n",
    "\n",
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(docs)\n",
    "pickle.dump(id2word, open( \"id2word.p\", \"wb\" ) )\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# supporting function\n",
    "def compute_coherence_values(corpus, dictionary, text, k, a, b):\n",
    "    \n",
    "    lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                           id2word=dictionary,\n",
    "                                           num_topics=k, \n",
    "                                           random_state=100,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha=a,\n",
    "                                           eta=b)\n",
    "    \n",
    "    coherence_model_lda = CoherenceModel(model=lda_model, texts=text, dictionary=id2word, coherence='c_v')\n",
    "    \n",
    "    return coherence_model_lda.get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {}\n",
    "grid['Validation_Set'] = {}\n",
    "\n",
    "nb_words = len(id2word)\n",
    "\n",
    "# Topics range\n",
    "min_topics = 6\n",
    "max_topics = 10\n",
    "step_size = 1\n",
    "# topics_range = range(min_topics, max_topics, step_size)\n",
    "topics_range = [8]\n",
    "# Alpha parameter\n",
    "# Added in the loop\n",
    "\n",
    "# Alpha\n",
    "alpha = [\n",
    "#     0.1, \n",
    "#     'symmetric',\n",
    "#     'asymmetric'\n",
    "]\n",
    "\n",
    "# Beta parameter\n",
    "beta = [\n",
    "    0.1, \n",
    "#     200/nb_words\n",
    "]\n",
    "beta.append('symmetric')\n",
    "\n",
    "# Validation sets\n",
    "num_of_docs = len(corpus)\n",
    "corpus_sets = [\n",
    "#     gensim.utils.ClippedCorpus(corpus, num_of_docs*0.05), \n",
    "#     gensim.utils.ClippedCorpus(corpus, num_of_docs*0.5), \n",
    "#     gensim.utils.ClippedCorpus(corpus, num_of_docs*0.75), \n",
    "    corpus\n",
    "]\n",
    "\n",
    "corpus_title = [\n",
    "#     '25% Corpus',\n",
    "#     '50% Corpus',\n",
    "#     '75% Corpus',\n",
    "    '100% Corpus'\n",
    "]\n",
    "\n",
    "model_results = {'Validation_Set': [],\n",
    "                 'Topics': [],\n",
    "                 'Alpha': [],\n",
    "                 'Beta': [],\n",
    "                 'Coherence': []\n",
    "                }\n",
    "\n",
    "# Can take a long time to run\n",
    "if 1 == 1:\n",
    "    pbar = tqdm.tqdm(total=(len(beta)*(len(alpha)+1)*len(topics_range)*len(corpus_title)))\n",
    "    # iterate through validation corpuses\n",
    "    for i in range(len(corpus_sets)):\n",
    "        # iterate through number of topics\n",
    "        for k in topics_range:\n",
    "            alpha.append(50/k)\n",
    "            # iterate through alpha values\n",
    "            for a in alpha:\n",
    "                # iterare through beta values\n",
    "                for b in beta:\n",
    "                    # get the coherence score for the given parameters\n",
    "                    cv = compute_coherence_values(corpus=corpus_sets[i], dictionary=id2word, text=docs,\n",
    "                                                  k=k, a=a, b=b)\n",
    "                    # Save the model results\n",
    "                    model_results['Validation_Set'].append(corpus_title[i])\n",
    "                    model_results['Topics'].append(k)\n",
    "                    model_results['Alpha'].append(a)\n",
    "                    model_results['Beta'].append(b)\n",
    "                    model_results['Coherence'].append(cv)\n",
    "                    pbar.update(1)\n",
    "    res = pd.DataFrame(model_results)\n",
    "    res = pd.DataFrame(model_results).sort_values(\"Coherence\", ascending=False)\n",
    "    res.to_csv('lda_tuning_results.csv', index=False)\n",
    "    pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_param = res.iloc[0]\n",
    "num_topics = best_param['Topics']\n",
    "alpha = best_param['Alpha']\n",
    "eta = best_param['Beta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LDA model\n",
    "int_start=time.time()\n",
    "lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                       id2word=id2word,\n",
    "                                       num_topics=num_topics,\n",
    "                                       alpha = alpha,\n",
    "                                       eta = eta,\n",
    "                                       random_state=100,\n",
    "                                       chunksize=100,\n",
    "                                       passes=10,\n",
    "                                       per_word_topics=True)\n",
    "print(time.time()-int_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=docs, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('Coherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "LDAvis_prepared = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n",
    "LDAvis_prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model.save('lda_test.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_pickle('reviews_concat.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.loc['2019']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# docs = list(tqdm.tqdm(preprocess(df.values.tolist(), stop_words), position=0, leave=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(docs, open( \"docs.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = pickle.load(open(\"docs.p\", \"rb\"))\n",
    "id2word = pickle.load(open(\"id2word.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lda_model = gen?sim.models.LdaModel.load('lda.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.concat([df.to_frame('description').reset_index(), pd.DataFrame(gensim.matutils.corpus2csc(lda_model.get_document_topics(corpus)).T.toarray(), columns=['topic_'+str(i) for i in range(1,num_topics+1)])], axis=1, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(gensim.matutils.corpus2csc(lda_model.get_document_topics(corpus)).T.toarray(), columns=['topic_'+str(i) for i in range(1,num_topics+1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_frame('description').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_pickle('reviews_w_topics_test.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Build the bigram and trigram models\n",
    "# bigram = gensim.models.Phrases(data_words, min_count=5, threshold=150) # higher threshold fewer phrases.\n",
    "# # trigram = gensim.models.Phrases(bigram[data_words], threshold=150)\n",
    "\n",
    "# # Faster way to get a sentence clubbed as a trigram/bigram\n",
    "# bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "# # trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "# def remove_stopwords(texts):\n",
    "#     return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "# def make_bigrams(texts):\n",
    "#     return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "# def make_trigrams(texts):\n",
    "#     return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "# def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "#     \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "#     texts_out = []\n",
    "#     for sent in texts:\n",
    "#         doc = nlp(\" \".join(sent)) \n",
    "#         texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "#     return texts_out\n",
    "\n",
    "# # Remove Stop Words\n",
    "# data_words = remove_stopwords(data_words)\n",
    "\n",
    "# # Do lemmatization keeping only noun, adj, vb, adv\n",
    "# data_words = lemmatization(data_words, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "\n",
    "# # Form Bigrams\n",
    "# data_words = make_bigrams(data_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Build LDA model\n",
    "# lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "#                                        id2word=id2word,\n",
    "#                                        num_topics=8, \n",
    "#                                        random_state=100,\n",
    "#                                        chunksize=100,\n",
    "#                                        passes=10,\n",
    "#                                        per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pprint(lda_model.print_topics())\n",
    "# doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "# coherence_lda = coherence_model_lda.get_coherence()\n",
    "# print('Coherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "200.156px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
