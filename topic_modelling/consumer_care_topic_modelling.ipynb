{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook pulls directly from: https://github.com/kapadias/mediumposts/blob/master/nlp/published_notebooks/Evaluate%20Topic%20Models.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\cfowle\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "if 0 == 1:\n",
    "    import nltk\n",
    "    nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-3.8.3-cp37-cp37m-win_amd64.whl (24.2 MB)\n",
      "Collecting Cython==0.29.14\n",
      "  Downloading Cython-0.29.14-cp37-cp37m-win_amd64.whl (1.7 MB)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\cfowle\\anaconda3\\lib\\site-packages (from gensim) (1.4.1)\n",
      "Collecting smart-open>=1.8.1\n",
      "  Downloading smart_open-2.0.0.tar.gz (103 kB)\n",
      "Requirement already satisfied: six>=1.5.0 in c:\\users\\cfowle\\anaconda3\\lib\\site-packages (from gensim) (1.14.0)\n",
      "Requirement already satisfied: numpy>=1.11.3 in c:\\users\\cfowle\\anaconda3\\lib\\site-packages (from gensim) (1.18.1)\n",
      "Requirement already satisfied: requests in c:\\users\\cfowle\\anaconda3\\lib\\site-packages (from smart-open>=1.8.1->gensim) (2.22.0)\n",
      "Requirement already satisfied: boto in c:\\users\\cfowle\\anaconda3\\lib\\site-packages (from smart-open>=1.8.1->gensim) (2.49.0)\n",
      "Collecting boto3\n",
      "  Downloading boto3-1.14.10-py2.py3-none-any.whl (128 kB)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\cfowle\\anaconda3\\lib\\site-packages (from requests->smart-open>=1.8.1->gensim) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\cfowle\\anaconda3\\lib\\site-packages (from requests->smart-open>=1.8.1->gensim) (2019.11.28)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\cfowle\\anaconda3\\lib\\site-packages (from requests->smart-open>=1.8.1->gensim) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\cfowle\\anaconda3\\lib\\site-packages (from requests->smart-open>=1.8.1->gensim) (1.25.8)\n",
      "Collecting jmespath<1.0.0,>=0.7.1\n",
      "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting botocore<1.18.0,>=1.17.10\n",
      "  Downloading botocore-1.17.10-py2.py3-none-any.whl (6.3 MB)\n",
      "Collecting s3transfer<0.4.0,>=0.3.0\n",
      "  Downloading s3transfer-0.3.3-py2.py3-none-any.whl (69 kB)\n",
      "Collecting docutils<0.16,>=0.10\n",
      "  Downloading docutils-0.15.2-py3-none-any.whl (547 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\cfowle\\anaconda3\\lib\\site-packages (from botocore<1.18.0,>=1.17.10->boto3->smart-open>=1.8.1->gensim) (2.8.1)\n",
      "Building wheels for collected packages: smart-open\n",
      "  Building wheel for smart-open (setup.py): started\n",
      "  Building wheel for smart-open (setup.py): finished with status 'done'\n",
      "  Created wheel for smart-open: filename=smart_open-2.0.0-py3-none-any.whl size=101346 sha256=ac0b8ef83106567250d16df0a4791b1f2695e10572df588e26bac61d5032c4fb\n",
      "  Stored in directory: c:\\users\\cfowle\\appdata\\local\\pip\\cache\\wheels\\bb\\1c\\9c\\412ec03f6d5ac7d41f4b965bde3fc0d1bd201da5ba3e2636de\n",
      "Successfully built smart-open\n",
      "Installing collected packages: Cython, jmespath, docutils, botocore, s3transfer, boto3, smart-open, gensim\n",
      "  Attempting uninstall: Cython\n",
      "    Found existing installation: Cython 0.29.15\n",
      "    Uninstalling Cython-0.29.15:\n",
      "      Successfully uninstalled Cython-0.29.15\n",
      "  Attempting uninstall: docutils\n",
      "    Found existing installation: docutils 0.16\n",
      "    Uninstalling docutils-0.16:\n",
      "      Successfully uninstalled docutils-0.16\n",
      "Successfully installed Cython-0.29.14 boto3-1.14.10 botocore-1.17.10 docutils-0.15.2 gensim-3.8.3 jmespath-0.10.0 s3transfer-0.3.3 smart-open-2.0.0\n",
      "Collecting PyLDAvis\n",
      "  Downloading pyLDAvis-2.1.2.tar.gz (1.6 MB)\n",
      "Requirement already satisfied: wheel>=0.23.0 in c:\\users\\cfowle\\anaconda3\\lib\\site-packages (from PyLDAvis) (0.34.2)\n",
      "Requirement already satisfied: numpy>=1.9.2 in c:\\users\\cfowle\\anaconda3\\lib\\site-packages (from PyLDAvis) (1.18.1)\n",
      "Requirement already satisfied: scipy>=0.18.0 in c:\\users\\cfowle\\anaconda3\\lib\\site-packages (from PyLDAvis) (1.4.1)\n",
      "Requirement already satisfied: pandas>=0.17.0 in c:\\users\\cfowle\\anaconda3\\lib\\site-packages (from PyLDAvis) (1.0.1)\n",
      "Requirement already satisfied: joblib>=0.8.4 in c:\\users\\cfowle\\anaconda3\\lib\\site-packages (from PyLDAvis) (0.14.1)\n",
      "Requirement already satisfied: jinja2>=2.7.2 in c:\\users\\cfowle\\anaconda3\\lib\\site-packages (from PyLDAvis) (2.11.1)\n",
      "Requirement already satisfied: numexpr in c:\\users\\cfowle\\anaconda3\\lib\\site-packages (from PyLDAvis) (2.7.1)\n",
      "Requirement already satisfied: pytest in c:\\users\\cfowle\\anaconda3\\lib\\site-packages (from PyLDAvis) (5.3.5)\n",
      "Requirement already satisfied: future in c:\\users\\cfowle\\anaconda3\\lib\\site-packages (from PyLDAvis) (0.18.2)\n",
      "Collecting funcy\n",
      "  Downloading funcy-1.14.tar.gz (548 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\users\\cfowle\\anaconda3\\lib\\site-packages (from pandas>=0.17.0->PyLDAvis) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\cfowle\\anaconda3\\lib\\site-packages (from pandas>=0.17.0->PyLDAvis) (2019.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\cfowle\\anaconda3\\lib\\site-packages (from jinja2>=2.7.2->PyLDAvis) (1.1.1)\n",
      "Requirement already satisfied: py>=1.5.0 in c:\\users\\cfowle\\anaconda3\\lib\\site-packages (from pytest->PyLDAvis) (1.8.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\cfowle\\anaconda3\\lib\\site-packages (from pytest->PyLDAvis) (20.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\cfowle\\anaconda3\\lib\\site-packages (from pytest->PyLDAvis) (19.3.0)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in c:\\users\\cfowle\\anaconda3\\lib\\site-packages (from pytest->PyLDAvis) (8.2.0)\n",
      "Requirement already satisfied: pluggy<1.0,>=0.12 in c:\\users\\cfowle\\anaconda3\\lib\\site-packages (from pytest->PyLDAvis) (0.13.1)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\cfowle\\anaconda3\\lib\\site-packages (from pytest->PyLDAvis) (0.1.8)\n",
      "Requirement already satisfied: importlib-metadata>=0.12 in c:\\users\\cfowle\\anaconda3\\lib\\site-packages (from pytest->PyLDAvis) (1.5.0)\n",
      "Requirement already satisfied: atomicwrites>=1.0 in c:\\users\\cfowle\\anaconda3\\lib\\site-packages (from pytest->PyLDAvis) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\cfowle\\anaconda3\\lib\\site-packages (from pytest->PyLDAvis) (0.4.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\cfowle\\anaconda3\\lib\\site-packages (from python-dateutil>=2.6.1->pandas>=0.17.0->PyLDAvis) (1.14.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\cfowle\\anaconda3\\lib\\site-packages (from packaging->pytest->PyLDAvis) (2.4.6)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\cfowle\\anaconda3\\lib\\site-packages (from importlib-metadata>=0.12->pytest->PyLDAvis) (2.2.0)\n",
      "Building wheels for collected packages: PyLDAvis, funcy\n",
      "  Building wheel for PyLDAvis (setup.py): started\n",
      "  Building wheel for PyLDAvis (setup.py): finished with status 'done'\n",
      "  Created wheel for PyLDAvis: filename=pyLDAvis-2.1.2-py2.py3-none-any.whl size=97716 sha256=53f3d3161d9179bf0fe9a907e834db5d13f9ba1a2503e520a8be9b945eb87b7d\n",
      "  Stored in directory: c:\\users\\cfowle\\appdata\\local\\pip\\cache\\wheels\\3b\\fb\\41\\e32e5312da9f440d34c4eff0d2207b46dc9332a7b931ef1e89\n",
      "  Building wheel for funcy (setup.py): started\n",
      "  Building wheel for funcy (setup.py): finished with status 'done'\n",
      "  Created wheel for funcy: filename=funcy-1.14-py2.py3-none-any.whl size=32045 sha256=2f816783bcf22ee19dbc5fbe0336ab02dce3182e3bfc8950a1a073deba9d21f5\n",
      "  Stored in directory: c:\\users\\cfowle\\appdata\\local\\pip\\cache\\wheels\\3c\\33\\97\\805b282e129f60bb4e87cea622338f30b65f21eaf65219971f\n",
      "Successfully built PyLDAvis funcy\n",
      "Installing collected packages: funcy, PyLDAvis\n",
      "Successfully installed PyLDAvis-2.1.2 funcy-1.14\n",
      "Collecting spacy\n",
      "  Downloading spacy-2.3.0-cp37-cp37m-win_amd64.whl (9.4 MB)\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Downloading preshed-3.0.2-cp37-cp37m-win_amd64.whl (105 kB)\n",
      "Collecting catalogue<1.1.0,>=0.0.7\n",
      "  Downloading catalogue-1.0.0-py2.py3-none-any.whl (7.7 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\cfowle\\anaconda3\\lib\\site-packages (from spacy) (45.2.0.post20200210)\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Downloading cymem-2.0.3-cp37-cp37m-win_amd64.whl (32 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\cfowle\\anaconda3\\lib\\site-packages (from spacy) (4.42.1)\n",
      "Collecting srsly<1.1.0,>=1.0.2\n",
      "  Downloading srsly-1.0.2-cp37-cp37m-win_amd64.whl (179 kB)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\cfowle\\anaconda3\\lib\\site-packages (from spacy) (1.18.1)\n",
      "Collecting plac<1.2.0,>=0.9.6\n",
      "  Downloading plac-1.1.3-py2.py3-none-any.whl (20 kB)\n",
      "Collecting thinc==7.4.1\n",
      "  Downloading thinc-7.4.1-cp37-cp37m-win_amd64.whl (2.0 MB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\cfowle\\anaconda3\\lib\\site-packages (from spacy) (2.22.0)\n",
      "Collecting blis<0.5.0,>=0.4.0\n",
      "  Downloading blis-0.4.1-cp37-cp37m-win_amd64.whl (5.0 MB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Downloading murmurhash-1.0.2-cp37-cp37m-win_amd64.whl (20 kB)\n",
      "Collecting wasabi<1.1.0,>=0.4.0\n",
      "  Downloading wasabi-0.7.0.tar.gz (22 kB)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in c:\\users\\cfowle\\anaconda3\\lib\\site-packages (from catalogue<1.1.0,>=0.0.7->spacy) (1.5.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\cfowle\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.25.8)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\cfowle\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\cfowle\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\cfowle\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2019.11.28)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\cfowle\\anaconda3\\lib\\site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (2.2.0)\n",
      "Building wheels for collected packages: wasabi\n",
      "  Building wheel for wasabi (setup.py): started\n",
      "  Building wheel for wasabi (setup.py): finished with status 'done'\n",
      "  Created wheel for wasabi: filename=wasabi-0.7.0-py3-none-any.whl size=20838 sha256=807f5dcffd6ab646c9fcee7cad3e19c173397cbba330a620238575d5cf2ab384\n",
      "  Stored in directory: c:\\users\\cfowle\\appdata\\local\\pip\\cache\\wheels\\68\\38\\40\\b82a00fbe88220b7fd467c29a0018357066e14466151189e5a\n",
      "Successfully built wasabi\n",
      "Installing collected packages: murmurhash, cymem, preshed, catalogue, srsly, plac, wasabi, blis, thinc, spacy\n",
      "Successfully installed blis-0.4.1 catalogue-1.0.0 cymem-2.0.3 murmurhash-1.0.2 plac-1.1.3 preshed-3.0.2 spacy-2.3.0 srsly-1.0.2 thinc-7.4.1 wasabi-0.7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en_core_web_sm==2.3.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.0/en_core_web_sm-2.3.0.tar.gz (12.0 MB)\n",
      "Requirement already satisfied: spacy<2.4.0,>=2.3.0 in c:\\users\\cfowle\\anaconda3\\lib\\site-packages (from en_core_web_sm==2.3.0) (2.3.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\cfowle\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (4.42.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\cfowle\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (45.2.0.post20200210)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\cfowle\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (2.0.3)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in c:\\users\\cfowle\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (1.0.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\cfowle\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (3.0.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\cfowle\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (1.18.1)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in c:\\users\\cfowle\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (0.4.1)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in c:\\users\\cfowle\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (1.1.3)\n",
      "Requirement already satisfied: thinc==7.4.1 in c:\\users\\cfowle\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (7.4.1)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in c:\\users\\cfowle\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (1.0.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in c:\\users\\cfowle\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (0.7.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\cfowle\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (2.22.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\cfowle\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (1.0.2)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in c:\\users\\cfowle\\anaconda3\\lib\\site-packages (from catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (1.5.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\cfowle\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (1.25.8)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\cfowle\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\cfowle\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (2019.11.28)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\cfowle\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (3.0.4)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\cfowle\\anaconda3\\lib\\site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (2.2.0)\n",
      "Building wheels for collected packages: en-core-web-sm\n",
      "  Building wheel for en-core-web-sm (setup.py): started\n",
      "  Building wheel for en-core-web-sm (setup.py): finished with status 'done'\n",
      "  Created wheel for en-core-web-sm: filename=en_core_web_sm-2.3.0-py3-none-any.whl size=12048612 sha256=e843ef06fa4c70e6f7334c5608a7d37b7f45e1102fbbfdc212a139073348e1d6\n",
      "  Stored in directory: C:\\Users\\cfowle\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-m24_lhgm\\wheels\\71\\4a\\56\\e48f8ad9359a6780edd8cdd42955519b1a21d6365ad15628a2\n",
      "Successfully built en-core-web-sm\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-2.3.0\n",
      "[+] Download and installation successful\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "if 0 == 1:\n",
    "    !pip install gensim\n",
    "    !pip install PyLDAvis\n",
    "    !pip install spacy\n",
    "    !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "import spacy\n",
    "import tqdm\n",
    "\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "import gensim.corpora as corpora\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "import pyLDAvis.gensim\n",
    "import pickle \n",
    "import pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_drive_path = \"C:/Users/cfowle/The Estée Lauder Companies Inc/TeamAnis - General/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "FY20 = pd.read_excel(one_drive_path + \"Data/Consumer Care/July_2019-April_2020_Merged_Feedback.xlsx\")\n",
    "FY19 = pd.read_csv(one_drive_path + \"Data/Consumer Care/FY19.csv\")\n",
    "FY18 = pd.read_excel(one_drive_path + \"Data/Consumer Care/FY18.xlsx\")\n",
    "FY17 = pd.read_excel(one_drive_path + \"Data/Consumer Care/FY17.xlsx\")\n",
    "\n",
    "##combine different years\n",
    "FY19 = FY19.rename(columns = {\"Case Date Added\": \"Case Date\",\n",
    "                   \"Mapped Brand Name\": \"Mapped Brand\",\n",
    "                   \"Store Door Name\": \"Store Door\"})\n",
    "FY19[\"P6\"] = FY19[\"Product Code\"]\n",
    "\n",
    "FY18 = FY18.rename(columns = {\"Case Date Added\": \"Case Date\",\n",
    "                               \"Mapped Brand Name\": \"Mapped Brand\",\n",
    "                               \"Store Door Name\": \"Store Door\"})\n",
    "FY18[\"P6\"] = FY18[\"Product Code\"]\n",
    "\n",
    "FY17 = FY17.rename(columns = {\"Case Date Added\": \"Case Date\",\n",
    "                               \"Mapped Brand Name\": \"Mapped Brand\",\n",
    "                               \"Store Door Name\": \"Store Door\"})\n",
    "FY17[\"P6\"] = FY17[\"Product Code\"]\n",
    "\n",
    "cc_codes = pd.concat([FY20, FY19, FY18, FY17], axis = 0)\n",
    "cc_codes[\"Date Month\"] = pd.to_datetime(cc_codes['Date Month'])\n",
    "cc_codes = cc_codes.rename(columns = {\"Date Month\": \"month\"})\n",
    "cc_codes['P6'] = ['nan' if x[0] == 'nan' else str(x[0])[:6] for x in cc_codes[[\"P6\"]].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_codes.to_csv(one_drive_path + \"Data/Consumer Care/merged_cc_F17_FY20.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_codes  = cc_codes.dropna(subset = [\"Verbatim\"])\n",
    "cc_codes  = cc_codes.loc[cc_codes[\"Reportable Country\"] == 'United States of America']\n",
    "documents = cc_codes[\"Verbatim\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = documents.map(lambda x: re.sub('[,\\.!?]', '', x))\n",
    "documents = documents.map(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "\n",
    "data = documents.values.tolist()\n",
    "data_words = list(sent_to_words(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['can',\n",
       " 'you',\n",
       " 'help',\n",
       " 'me',\n",
       " 'find',\n",
       " 'out',\n",
       " 'this',\n",
       " 'information',\n",
       " 'found',\n",
       " 'this',\n",
       " 'product',\n",
       " 'in',\n",
       " 'my',\n",
       " 'closet',\n",
       " 'in',\n",
       " 'the',\n",
       " 'way',\n",
       " 'back']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_words[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)\n",
    "\n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['large', 'red', 'cystic', 'bump', 'face', 'initially', 'think', 'maybe', 'purge', 'give', 'sometime', 'keep', 'get', 'bad']\n"
     ]
    }
   ],
   "source": [
    "# Remove Stop Words\n",
    "data_words_nostops = remove_stopwords(data_words)\n",
    "\n",
    "# Form Bigrams\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)\n",
    "\n",
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=['parser', 'ner'])\n",
    "\n",
    "# Do lemmatization keeping only noun, adj, vb, adv\n",
    "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "\n",
    "print(data_lemmatized[:1][0][:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1)]\n"
     ]
    }
   ],
   "source": [
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "\n",
    "# Create Corpus\n",
    "texts = data_lemmatized\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "# View\n",
    "print(corpus[:1][0][:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LDA model\n",
    "lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                       id2word=id2word,\n",
    "                                       num_topics=7, \n",
    "                                       random_state=100,\n",
    "                                       chunksize=100,\n",
    "                                       passes=10,\n",
    "                                       per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.047*\"store\" + 0.036*\"go\" + 0.029*\"want\" + 0.028*\"buy\" + 0.024*\"tell\" + '\n",
      "  '0.024*\"say\" + 0.022*\"return\" + 0.020*\"get\" + 0.020*\"purchase\" + '\n",
      "  '0.019*\"product\"'),\n",
      " (1,\n",
      "  '0.073*\"order\" + 0.032*\"get\" + 0.030*\"online\" + 0.029*\"receive\" + '\n",
      "  '0.025*\"gift\" + 0.020*\"email\" + 0.020*\"place\" + 0.018*\"call\" + 0.015*\"card\" '\n",
      "  '+ 0.015*\"want\"'),\n",
      " (2,\n",
      "  '0.065*\"use\" + 0.035*\"skin\" + 0.026*\"face\" + 0.024*\"get\" + 0.022*\"eye\" + '\n",
      "  '0.022*\"day\" + 0.019*\"product\" + 0.017*\"go\" + 0.017*\"time\" + 0.015*\"start\"'),\n",
      " (3,\n",
      "  '0.029*\"open\" + 0.026*\"damage\" + 0.025*\"box\" + 0.022*\"send\" + '\n",
      "  '0.022*\"product\" + 0.017*\"top\" + 0.014*\"salon\" + 0.012*\"replacement\" + '\n",
      "  '0.011*\"picture\" + 0.011*\"break\"'),\n",
      " (4,\n",
      "  '0.064*\"would\" + 0.058*\"product\" + 0.026*\"love\" + 0.021*\"know\" + '\n",
      "  '0.020*\"like\" + 0.015*\"could\" + 0.013*\"sample\" + 0.012*\"want\" + '\n",
      "  '0.012*\"company\" + 0.012*\"ingredient\"'),\n",
      " (5,\n",
      "  '0.053*\"product\" + 0.025*\"hair\" + 0.024*\"use\" + 0.023*\"year\" + '\n",
      "  '0.017*\"purchase\" + 0.017*\"bottle\" + 0.015*\"buy\" + 0.014*\"love\" + '\n",
      "  '0.012*\"smell\" + 0.010*\"time\"'),\n",
      " (6,\n",
      "  '0.088*\"look\" + 0.063*\"color\" + 0.040*\"product\" + 0.036*\"shade\" + '\n",
      "  '0.030*\"name\" + 0.029*\"be\" + 0.024*\"discontinue\" + 0.024*\"lipstick\" + '\n",
      "  '0.021*\"brand\" + 0.019*\"find\"')]\n"
     ]
    }
   ],
   "source": [
    "# Print the Keyword in the 10 topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score:  0.5707012021165434\n"
     ]
    }
   ],
   "source": [
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('Coherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# supporting function\n",
    "def compute_coherence_values(corpus, dictionary, k, a, b):\n",
    "    \n",
    "    lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                           id2word=dictionary,\n",
    "                                           num_topics=k, \n",
    "                                           random_state=100,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha=a,\n",
    "                                           eta=b)\n",
    "    \n",
    "    coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "    \n",
    "    return coherence_model_lda.get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 4/270 [1:38:25<108:18:19, 1465.79s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-82-f0ac09eb4590>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     47\u001b[0m                     \u001b[1;31m# get the coherence score for the given parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m                     cv = compute_coherence_values(corpus=corpus_sets[i], dictionary=id2word, \n\u001b[1;32m---> 49\u001b[1;33m                                                   k=k, a=a, b=b)\n\u001b[0m\u001b[0;32m     50\u001b[0m                     \u001b[1;31m# Save the model results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m                     \u001b[0mmodel_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Validation_Set'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus_title\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-81-ad0dd2c2e33b>\u001b[0m in \u001b[0;36mcompute_coherence_values\u001b[1;34m(corpus, dictionary, k, a, b)\u001b[0m\n\u001b[0;32m      9\u001b[0m                                            \u001b[0mpasses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m                                            \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m                                            eta=b)\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mcoherence_model_lda\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCoherenceModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlda_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtexts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_lemmatized\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mid2word\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoherence\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c_v'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gensim\\models\\ldamulticore.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, corpus, num_topics, id2word, workers, chunksize, passes, batch, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, random_state, minimum_probability, minimum_phi_value, per_word_topics, dtype)\u001b[0m\n\u001b[0;32m    182\u001b[0m             \u001b[0mdecay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecay\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moffset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_every\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_every\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0miterations\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m             \u001b[0mgamma_threshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgamma_threshold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminimum_probability\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mminimum_probability\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 184\u001b[1;33m             \u001b[0mminimum_phi_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mminimum_phi_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mper_word_topics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mper_word_topics\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    185\u001b[0m         )\n\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gensim\\models\\ldamodel.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, corpus, num_topics, id2word, distributed, chunksize, passes, update_every, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, minimum_probability, random_state, ns_conf, minimum_phi_value, per_word_topics, callbacks, dtype)\u001b[0m\n\u001b[0;32m    517\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m             \u001b[0muse_numpy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatcher\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 519\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunks_as_numpy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_numpy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    520\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minit_dir_prior\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprior\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gensim\\models\\ldamulticore.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, corpus, chunks_as_numpy)\u001b[0m\n\u001b[0;32m    303\u001b[0m                         \u001b[0mprocess_result_queue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 305\u001b[1;33m                 \u001b[0mprocess_result_queue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    306\u001b[0m             \u001b[1;31m# endfor single corpus pass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gensim\\models\\ldamulticore.py\u001b[0m in \u001b[0;36mprocess_result_queue\u001b[1;34m(force)\u001b[0m\n\u001b[0;32m    266\u001b[0m             \"\"\"\n\u001b[0;32m    267\u001b[0m             \u001b[0mmerged_new\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 268\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mresult_queue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    269\u001b[0m                 \u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult_queue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m                 \u001b[0mqueue_size\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\queues.py\u001b[0m in \u001b[0;36mempty\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\connection.py\u001b[0m in \u001b[0;36mpoll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\connection.py\u001b[0m in \u001b[0;36m_poll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    326\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m             if (self._got_empty_message or\n\u001b[1;32m--> 328\u001b[1;33m                         _winapi.PeekNamedPipe(self._handle)[0] != 0):\n\u001b[0m\u001b[0;32m    329\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "grid = {}\n",
    "grid['Validation_Set'] = {}\n",
    "\n",
    "# Topics range\n",
    "min_topics = 2\n",
    "max_topics = 11\n",
    "step_size = 1\n",
    "topics_range = range(min_topics, max_topics, step_size)\n",
    "\n",
    "# Alpha parameter\n",
    "alpha = list(np.arange(0.01, 1, 0.3))\n",
    "alpha.append('symmetric')\n",
    "alpha.append('asymmetric')\n",
    "\n",
    "# Beta parameter\n",
    "beta = list(np.arange(0.01, 1, 0.3))\n",
    "beta.append('symmetric')\n",
    "\n",
    "# Validation sets\n",
    "num_of_docs = len(corpus)\n",
    "corpus_sets = [# gensim.utils.ClippedCorpus(corpus, num_of_docs*0.25), \n",
    "               # gensim.utils.ClippedCorpus(corpus, num_of_docs*0.5), \n",
    "               # gensim.utils.ClippedCorpus(corpus, num_of_docs*0.75), \n",
    "               corpus]\n",
    "\n",
    "corpus_title = ['100% Corpus']\n",
    "\n",
    "model_results = {'Validation_Set': [],\n",
    "                 'Topics': [],\n",
    "                 'Alpha': [],\n",
    "                 'Beta': [],\n",
    "                 'Coherence': []\n",
    "                }\n",
    "\n",
    "# Can take a long time to run\n",
    "if 1 == 1:\n",
    "    pbar = tqdm.tqdm(total=(len(beta)*len(alpha)*len(topics_range)*len(corpus_title)))\n",
    "    \n",
    "    # iterate through validation corpuses\n",
    "    for i in range(len(corpus_sets)):\n",
    "        # iterate through number of topics\n",
    "        for k in topics_range:\n",
    "            # iterate through alpha values\n",
    "            for a in alpha:\n",
    "                # iterare through beta values\n",
    "                for b in beta:\n",
    "                    # get the coherence score for the given parameters\n",
    "                    cv = compute_coherence_values(corpus=corpus_sets[i], dictionary=id2word, \n",
    "                                                  k=k, a=a, b=b)\n",
    "                    # Save the model results\n",
    "                    model_results['Validation_Set'].append(corpus_title[i])\n",
    "                    model_results['Topics'].append(k)\n",
    "                    model_results['Alpha'].append(a)\n",
    "                    model_results['Beta'].append(b)\n",
    "                    model_results['Coherence'].append(cv)\n",
    "                    \n",
    "                    pbar.update(1)\n",
    "    pd.DataFrame(model_results).to_csv('lda_tuning_results.csv', index=False)\n",
    "    pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el176426386986637522295364953\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el176426386986637522295364953_data = {\"mdsDat\": {\"x\": [0.15004839887705387, 0.07002033825582059, 0.02458595805894478, 0.13204259658799214, -0.003690517446017255, 0.049272687907239335, -0.4222794622410341], \"y\": [-0.11878705847013497, 0.06981034206591928, 0.04363900822071325, -0.036537213566310824, 0.3337689275605499, -0.22339382363293084, -0.06850018217780575], \"topics\": [1, 2, 3, 4, 5, 6, 7], \"cluster\": [1, 1, 1, 1, 1, 1, 1], \"Freq\": [20.012102127075195, 15.807926177978516, 15.266879081726074, 14.823844909667969, 13.913451194763184, 12.986085891723633, 7.1897125244140625]}, \"tinfo\": {\"Term\": [\"look\", \"order\", \"use\", \"color\", \"store\", \"would\", \"shade\", \"skin\", \"name\", \"online\", \"product\", \"get\", \"receive\", \"go\", \"hair\", \"face\", \"want\", \"buy\", \"gift\", \"be\", \"discontinue\", \"love\", \"eye\", \"return\", \"lipstick\", \"say\", \"brand\", \"send\", \"like\", \"open\", \"store\", \"receipt\", \"exchange\", \"service\", \"location\", \"manager\", \"discount\", \"counter\", \"appointment\", \"promotion\", \"employee\", \"rude\", \"walk\", \"policy\", \"macy\", \"expire\", \"associate\", \"waste\", \"helpful\", \"mall\", \"staff\", \"corporate\", \"poor\", \"bother\", \"complain\", \"ulta\", \"attitude\", \"schedule\", \"refuse\", \"applicator\", \"return\", \"sale\", \"girl\", \"customer\", \"home\", \"tell\", \"ask\", \"assist\", \"person\", \"go\", \"say\", \"buy\", \"want\", \"back\", \"close\", \"money\", \"call\", \"wrong\", \"help\", \"purchase\", \"give\", \"take\", \"get\", \"could\", \"make\", \"know\", \"need\", \"product\", \"come\", \"time\", \"try\", \"would\", \"makeup\", \"day\", \"hair\", \"smell\", \"conditioner\", \"fragrance\", \"spray\", \"pump\", \"easy\", \"scent\", \"plastic\", \"super\", \"expensive\", \"bumble\", \"aveda\", \"stylist\", \"cut\", \"user\", \"sulfate\", \"lash\", \"thick\", \"cleanser\", \"fresh\", \"thin\", \"calm\", \"cheap\", \"spill\", \"terrible\", \"remedy\", \"design\", \"recycle\", \"hairspray\", \"quite\", \"bottle\", \"head\", \"formula\", \"shampoo\", \"perfume\", \"change\", \"shampure\", \"brush\", \"year\", \"size\", \"old\", \"quality\", \"always\", \"body\", \"great\", \"product\", \"good\", \"new\", \"many\", \"use\", \"purchase\", \"love\", \"recently\", \"buy\", \"full\", \"time\", \"make\", \"work\", \"find\", \"long\", \"come\", \"try\", \"last\", \"like\", \"interested\", \"review\", \"beauty\", \"reach\", \"event\", \"instagram\", \"gluten\", \"follower\", \"appreciate\", \"currently\", \"opportunity\", \"influencer\", \"consider\", \"promote\", \"share\", \"support\", \"post\", \"collaborate\", \"team\", \"collaboration\", \"candle\", \"skincare\", \"photo\", \"school\", \"donation\", \"student\", \"wholesale\", \"partner\", \"chemical\", \"list\", \"company\", \"would\", \"ingredient\", \"contain\", \"love\", \"sample\", \"wonder\", \"product\", \"could\", \"know\", \"contact\", \"brand\", \"thank\", \"work\", \"makeup\", \"hope\", \"send\", \"want\", \"see\", \"provide\", \"let\", \"try\", \"free\", \"look\", \"make\", \"help\", \"face\", \"red\", \"reaction\", \"night\", \"cause\", \"allergic\", \"burn\", \"rash\", \"itch\", \"sensitive\", \"mask\", \"bump\", \"redness\", \"later\", \"cheek\", \"repair\", \"breakout\", \"normal\", \"twice\", \"pimple\", \"itchy\", \"spot\", \"oily\", \"irritated\", \"acne\", \"dermatologist\", \"neck\", \"wake\", \"hot\", \"peel\", \"skin\", \"stop\", \"use\", \"start\", \"morning\", \"day\", \"eye\", \"break\", \"dry\", \"happen\", \"cream\", \"week\", \"notice\", \"away\", \"little\", \"month\", \"time\", \"get\", \"ago\", \"first\", \"bad\", \"go\", \"put\", \"feel\", \"think\", \"product\", \"try\", \"last\", \"take\", \"make\", \"buy\", \"color\", \"shade\", \"name\", \"discontinue\", \"powder\", \"compact\", \"pure\", \"gloss\", \"press\", \"mother\", \"blush\", \"brown\", \"palette\", \"bobbi_brown\", \"eyeshadow\", \"coverage\", \"discontinued\", \"collection\", \"acne_solution\", \"rise\", \"friendly\", \"tint\", \"membership\", \"honey\", \"neutral\", \"paraben\", \"rich\", \"shine\", \"up\", \"blend\", \"look\", \"shadow\", \"lipstick\", \"lip\", \"light\", \"piece\", \"wear\", \"liner\", \"be\", \"pink\", \"origin\", \"double\", \"brand\", \"pencil\", \"search\", \"available\", \"concealer\", \"eyeliner\", \"clinique\", \"find\", \"black\", \"comment\", \"foundation\", \"long\", \"product\", \"eye\", \"makeup\", \"last\", \"year\", \"stock\", \"thank\", \"know\", \"call\", \"order\", \"online\", \"receive\", \"gift\", \"place\", \"card\", \"address\", \"code\", \"shipping\", \"birthday\", \"ship\", \"airport\", \"sign\", \"cancel\", \"video\", \"transfer\", \"reward\", \"wanted\", \"feature\", \"checkout\", \"book\", \"pm\", \"busy\", \"certificate\", \"promotional\", \"makeover\", \"bonus\", \"frustrated\", \"promo\", \"sonic\", \"mail\", \"charge\", \"email\", \"point\", \"wait\", \"number\", \"phone\", \"label\", \"website\", \"check\", \"account\", \"free\", \"speak\", \"item\", \"get\", \"call\", \"information\", \"send\", \"need\", \"say\", \"want\", \"try\", \"see\", \"sample\", \"offer\", \"purchase\", \"give\", \"would\", \"know\", \"damage\", \"box\", \"top\", \"picture\", \"leak\", \"consumer\", \"animal\", \"page\", \"cap\", \"container\", \"curly\", \"move\", \"nee\", \"liter\", \"info\", \"form\", \"sharpen\", \"confirm\", \"solution\", \"mention\", \"damaged_insufficient\", \"colour\", \"carmine\", \"accept\", \"damaged\", \"early\", \"fashion\", \"production\", \"separate\", \"pack\", \"open\", \"lady\", \"replacement\", \"packaging\", \"salon\", \"send\", \"credit\", \"break\", \"tube\", \"amount\", \"follow\", \"product\", \"item\", \"come\", \"state\", \"package\", \"pencil\", \"back\"], \"Freq\": [62265.0, 43954.0, 61673.0, 40396.0, 43833.0, 62472.0, 23168.0, 23904.0, 19130.0, 18223.0, 142278.0, 57466.0, 17506.0, 51756.0, 18381.0, 17658.0, 44823.0, 41856.0, 15231.0, 24623.0, 15560.0, 30513.0, 23512.0, 23716.0, 17681.0, 32877.0, 21610.0, 21177.0, 14147.0, 12036.0, 43832.41796875, 9261.576171875, 8569.1259765625, 7739.55029296875, 4282.26025390625, 3481.472412109375, 2986.90869140625, 2955.571044921875, 2666.34130859375, 2540.283447265625, 2505.521728515625, 2267.962890625, 1990.86572265625, 1960.2664794921875, 1941.01171875, 1869.8023681640625, 1767.3399658203125, 1766.20654296875, 1716.6334228515625, 1672.1893310546875, 1326.0245361328125, 793.6847534179688, 792.8048095703125, 724.0123291015625, 715.5364990234375, 701.2432250976562, 680.294677734375, 680.4573974609375, 677.5682373046875, 622.3536987304688, 20661.921875, 5031.98046875, 3846.910888671875, 11794.9228515625, 4536.44775390625, 22556.71875, 9564.853515625, 1619.248779296875, 3370.31884765625, 33327.95703125, 22006.19921875, 25558.033203125, 26887.474609375, 16151.94140625, 3602.6728515625, 3672.85107421875, 16030.2451171875, 4991.8203125, 11706.9736328125, 18128.05859375, 10795.8125, 10407.0078125, 18326.66015625, 9944.5068359375, 11529.1904296875, 13084.4658203125, 8801.2255859375, 17607.5390625, 6736.55126953125, 8666.138671875, 8865.6201171875, 9053.6533203125, 6328.63720703125, 6207.9833984375, 18380.671875, 8947.5751953125, 7170.6953125, 5112.353515625, 4508.3896484375, 4171.70703125, 3879.126953125, 3696.32373046875, 2331.05615234375, 2013.608642578125, 1893.55224609375, 1804.9991455078125, 1709.6119384765625, 1367.2381591796875, 1305.635009765625, 1252.3154296875, 1221.2491455078125, 1203.4063720703125, 1106.199951171875, 1040.103271484375, 959.1575317382812, 899.7914428710938, 897.2550659179688, 881.3937377929688, 876.2891845703125, 1578.9176025390625, 865.8195190429688, 844.2236938476562, 829.149169921875, 824.0333251953125, 1819.109619140625, 12378.705078125, 1606.562255859375, 4867.1689453125, 5860.48291015625, 4247.40087890625, 7478.5224609375, 2060.795654296875, 4298.75390625, 16564.298828125, 4264.09326171875, 5182.845703125, 2587.35546875, 5400.20556640625, 3362.682861328125, 5417.0166015625, 38414.4375, 7303.5517578125, 7487.2548828125, 4930.72021484375, 17439.025390625, 12524.154296875, 10052.533203125, 5028.8154296875, 11128.646484375, 3879.032958984375, 7543.18115234375, 7454.45947265625, 5580.24853515625, 5584.03662109375, 5167.6318359375, 4617.64404296875, 4586.54345703125, 4400.18310546875, 14146.478515625, 6485.24365234375, 5728.26611328125, 4564.53564453125, 4246.62451171875, 3413.740966796875, 3219.89208984375, 3098.876220703125, 2804.261962890625, 2643.843505859375, 2503.34423828125, 2432.195068359375, 2403.302001953125, 2373.111328125, 2349.4130859375, 2297.19384765625, 2187.006103515625, 2169.831787109375, 2005.8505859375, 1865.4940185546875, 1705.648193359375, 1684.873046875, 1638.96337890625, 1615.820068359375, 1591.16748046875, 1534.636962890625, 1428.82666015625, 1261.20703125, 1241.504638671875, 1191.478515625, 7154.890625, 8704.2255859375, 45182.27734375, 8634.134765625, 4478.40771484375, 18200.50390625, 9445.8779296875, 7387.86279296875, 40673.29296875, 10432.42578125, 14643.3134765625, 4078.48193359375, 8006.5, 6393.09033203125, 7293.8203125, 7152.67919921875, 4070.310791015625, 6720.57666015625, 8759.310546875, 6057.87548828125, 3236.35107421875, 4050.01513671875, 6007.87060546875, 4535.31689453125, 5786.67236328125, 4449.916015625, 4209.46240234375, 17657.599609375, 8882.9072265625, 6534.6142578125, 5667.505859375, 4869.80859375, 4785.56103515625, 4560.77490234375, 3560.4951171875, 3150.34326171875, 3131.174072265625, 2703.0439453125, 2654.371337890625, 2232.51513671875, 2169.41845703125, 2154.864990234375, 2152.657470703125, 2111.0703125, 1781.47509765625, 1768.7987060546875, 1704.53173828125, 1658.4569091796875, 1647.087158203125, 1519.2413330078125, 1494.9005126953125, 1325.1285400390625, 1271.0357666015625, 1256.9910888671875, 1219.7325439453125, 1096.0126953125, 988.165283203125, 23807.90234375, 8095.6171875, 44234.17578125, 9999.6298828125, 2958.375732421875, 14949.046875, 15089.20703125, 8634.7529296875, 6916.5986328125, 6254.87109375, 7402.56005859375, 8206.2392578125, 4533.94580078125, 4693.11474609375, 4856.37646484375, 5948.40771484375, 11432.810546875, 16421.1875, 6518.93359375, 5923.4453125, 4820.61181640625, 11860.92578125, 5473.33251953125, 6011.9248046875, 6380.99658203125, 12714.7001953125, 7492.171875, 5627.80712890625, 5539.1015625, 5397.24072265625, 5169.19482421875, 40395.7578125, 23168.056640625, 19129.646484375, 15559.2978515625, 7960.60791015625, 3445.97509765625, 2878.182373046875, 2154.92333984375, 1646.80517578125, 1587.06982421875, 1446.2110595703125, 1437.93603515625, 1347.53076171875, 1337.7095947265625, 1256.808349609375, 1253.8487548828125, 1228.1031494140625, 1225.6278076171875, 1046.3699951171875, 1015.9546508789062, 1002.9279174804688, 994.11669921875, 960.035400390625, 878.7865600585938, 863.1893310546875, 795.916259765625, 779.5438842773438, 778.4567260742188, 715.977294921875, 678.9325561523438, 56477.8828125, 4805.11181640625, 15317.86328125, 10743.94921875, 5826.4248046875, 4184.3681640625, 9389.7021484375, 4125.0458984375, 18905.224609375, 2506.603759765625, 4652.21875, 3069.2490234375, 13603.46484375, 5087.49853515625, 2544.3447265625, 6061.2314453125, 3163.65576171875, 2128.200439453125, 8409.4423828125, 12369.884765625, 2940.5087890625, 3030.902099609375, 5927.94384765625, 7373.6953125, 25718.619140625, 8422.740234375, 5696.4912109375, 5072.1083984375, 4388.6513671875, 3224.215576171875, 3453.944580078125, 3534.24169921875, 3471.6826171875, 43953.296875, 18222.19921875, 17505.236328125, 15230.875, 12066.599609375, 9061.8662109375, 5283.61083984375, 3699.768798828125, 3510.359375, 2970.38427734375, 2920.294677734375, 2410.722900390625, 1975.0787353515625, 1876.978759765625, 1830.2718505859375, 1725.364013671875, 1700.9619140625, 1170.9356689453125, 1153.232666015625, 1113.6015625, 1051.7012939453125, 1012.0257568359375, 997.8975219726562, 984.2570190429688, 876.967041015625, 871.4039916992188, 850.03466796875, 845.2092895507812, 730.78271484375, 721.8617553710938, 2533.768798828125, 4803.92138671875, 12181.6162109375, 4732.43359375, 3375.708251953125, 8272.0810546875, 2780.632568359375, 2382.43603515625, 5825.52685546875, 4949.58251953125, 4002.78515625, 8452.0634765625, 3226.286376953125, 8688.0087890625, 18990.865234375, 10940.958984375, 3657.38720703125, 7125.92333984375, 6598.94677734375, 7906.32470703125, 8727.083984375, 7885.30224609375, 5559.78173828125, 4502.02099609375, 3834.05859375, 5056.85498046875, 4179.60107421875, 4034.75048828125, 3725.02392578125, 8624.0087890625, 8335.4599609375, 5766.3359375, 3729.991455078125, 3467.30908203125, 2829.005126953125, 2586.236572265625, 2545.70751953125, 2507.636474609375, 2840.045654296875, 1519.0941162109375, 1494.3463134765625, 1493.024658203125, 1442.7325439453125, 1442.1944580078125, 1420.69580078125, 1353.3238525390625, 1269.3404541015625, 1254.5673828125, 1230.609130859375, 1210.76513671875, 1200.772216796875, 1196.9296875, 1190.778076171875, 1178.119384765625, 1161.0833740234375, 1075.0428466796875, 976.2348022460938, 918.7525634765625, 891.4085083007812, 9552.4990234375, 2307.42431640625, 4078.228515625, 3247.786865234375, 4629.0322265625, 7330.4423828125, 3250.194091796875, 3547.808349609375, 2149.528564453125, 1693.9329833984375, 1992.8046875, 7149.19091796875, 3167.868408203125, 2690.49658203125, 1649.7183837890625, 1794.1944580078125, 1659.189697265625, 1501.7352294921875], \"Total\": [62265.0, 43954.0, 61673.0, 40396.0, 43833.0, 62472.0, 23168.0, 23904.0, 19130.0, 18223.0, 142278.0, 57466.0, 17506.0, 51756.0, 18381.0, 17658.0, 44823.0, 41856.0, 15231.0, 24623.0, 15560.0, 30513.0, 23512.0, 23716.0, 17681.0, 32877.0, 21610.0, 21177.0, 14147.0, 12036.0, 43833.26171875, 9262.419921875, 8569.9697265625, 7740.3955078125, 4283.1044921875, 3482.31689453125, 2987.754638671875, 2956.415771484375, 2667.185546875, 2541.129638671875, 2506.366455078125, 2268.80615234375, 1991.710205078125, 1961.110595703125, 1941.8568115234375, 1870.648193359375, 1768.18408203125, 1767.054443359375, 1717.478759765625, 1673.0340576171875, 1326.8690185546875, 794.5302124023438, 793.65087890625, 724.860107421875, 716.3821411132812, 702.0895385742188, 681.1387329101562, 681.3028564453125, 678.4130249023438, 623.1998291015625, 23716.291015625, 5447.2060546875, 4183.86669921875, 13961.67578125, 5057.427734375, 29634.033203125, 11691.2998046875, 1733.933837890625, 3949.43408203125, 51756.89453125, 32877.96484375, 41856.4453125, 44823.02734375, 27127.966796875, 4330.00146484375, 4468.3017578125, 30443.447265625, 6675.208984375, 21299.58203125, 39339.4453125, 20495.40625, 19803.865234375, 57466.62109375, 23631.642578125, 31723.302734375, 40079.5390625, 20924.69921875, 142278.609375, 17067.54296875, 31619.53515625, 36513.859375, 62472.79296875, 21248.56640625, 22145.47265625, 18381.515625, 8948.4189453125, 7171.54052734375, 5113.1982421875, 4509.234375, 4172.55224609375, 3879.9716796875, 3697.168212890625, 2331.901611328125, 2014.454833984375, 1894.3975830078125, 1805.8438720703125, 1710.45703125, 1368.0831298828125, 1306.4803466796875, 1253.161376953125, 1222.0936279296875, 1204.2528076171875, 1107.045166015625, 1040.9503173828125, 960.0035400390625, 900.6366577148438, 898.1036376953125, 882.2394409179688, 877.1417236328125, 1580.4588623046875, 866.6666259765625, 845.0704956054688, 829.9947509765625, 824.880615234375, 1843.8748779296875, 13766.138671875, 1654.3680419921875, 5366.01611328125, 6881.23779296875, 5010.4072265625, 9582.46875, 2334.84228515625, 5508.640625, 27378.892578125, 5526.3564453125, 7158.60986328125, 3099.757080078125, 7896.5751953125, 4591.6826171875, 8782.203125, 142278.609375, 14224.0107421875, 15423.7470703125, 8555.8427734375, 61673.90625, 39339.4453125, 30513.5078125, 9727.9599609375, 41856.4453125, 6472.7451171875, 31619.53515625, 31723.302734375, 21196.19921875, 25324.8984375, 16960.93359375, 17067.54296875, 36513.859375, 18404.04296875, 14147.3212890625, 6486.08544921875, 5729.10791015625, 4565.37744140625, 4247.466796875, 3414.582763671875, 3220.732666015625, 3099.71728515625, 2805.1025390625, 2644.68603515625, 2504.186767578125, 2433.0361328125, 2404.142578125, 2373.954833984375, 2350.25390625, 2298.035400390625, 2187.848388671875, 2170.673583984375, 2006.691162109375, 1866.336181640625, 1706.48876953125, 1685.7166748046875, 1639.8056640625, 1616.666259765625, 1592.009765625, 1535.477783203125, 1429.6688232421875, 1262.048095703125, 1242.3460693359375, 1192.3236083984375, 7629.0732421875, 10034.9423828125, 62472.79296875, 10336.724609375, 5157.140625, 30513.5078125, 14424.1611328125, 12253.017578125, 142278.609375, 23631.642578125, 40079.5390625, 6366.6083984375, 21610.671875, 14578.470703125, 21196.19921875, 21248.56640625, 7104.00146484375, 21177.4921875, 44823.02734375, 22854.703125, 4870.5625, 9642.0478515625, 36513.859375, 16243.4091796875, 62265.26171875, 31723.302734375, 21299.58203125, 17658.443359375, 8883.75, 6535.4580078125, 5668.349609375, 4870.6533203125, 4786.4052734375, 4561.61767578125, 3561.337646484375, 3151.185791015625, 3132.017822265625, 2703.888427734375, 2655.2138671875, 2233.35791015625, 2170.26416015625, 2155.70849609375, 2153.502685546875, 2111.912841796875, 1782.31982421875, 1769.64404296875, 1705.374267578125, 1659.2994384765625, 1647.9310302734375, 1520.0849609375, 1495.7435302734375, 1325.97216796875, 1271.8787841796875, 1257.8341064453125, 1220.5751953125, 1096.8577880859375, 989.0084228515625, 23904.58203125, 9219.1396484375, 61673.90625, 12689.376953125, 3329.2060546875, 22145.47265625, 23512.65625, 12183.26171875, 9367.453125, 8492.375, 10489.1474609375, 12063.6806640625, 6396.67041015625, 6943.99072265625, 7710.6259765625, 10958.60546875, 31619.53515625, 57466.62109375, 12933.234375, 11401.6806640625, 7908.130859375, 51756.89453125, 10309.197265625, 13048.0712890625, 16494.681640625, 142278.609375, 36513.859375, 18404.04296875, 19803.865234375, 31723.302734375, 41856.4453125, 40396.60546875, 23168.904296875, 19130.494140625, 15560.146484375, 7961.45751953125, 3446.82373046875, 2879.0322265625, 2155.771728515625, 1647.655517578125, 1587.9241943359375, 1447.060791015625, 1438.7857666015625, 1348.380615234375, 1338.55859375, 1257.6573486328125, 1254.6982421875, 1228.9521484375, 1226.4796142578125, 1047.220703125, 1016.8042602539062, 1003.7825317382812, 994.9661865234375, 960.8876953125, 879.6354370117188, 864.0374145507812, 796.7677001953125, 780.3935546875, 779.306640625, 716.8385009765625, 679.7826538085938, 62265.26171875, 5172.93798828125, 17681.673828125, 12450.8974609375, 6534.93310546875, 4600.75830078125, 11072.287109375, 4578.45849609375, 24623.212890625, 2797.83544921875, 5797.0869140625, 3659.622802734375, 21610.671875, 6747.3935546875, 2949.81201171875, 8804.455078125, 3937.5625, 2413.337158203125, 14125.865234375, 25324.8984375, 3734.7216796875, 3896.447998046875, 10190.2822265625, 16960.93359375, 142278.609375, 23512.65625, 21248.56640625, 18404.04296875, 27378.892578125, 5405.6708984375, 14578.470703125, 40079.5390625, 30443.447265625, 43954.12890625, 18223.03125, 17506.0703125, 15231.7080078125, 12067.4326171875, 9062.6982421875, 5284.443359375, 3700.60205078125, 3511.192138671875, 2971.217041015625, 2921.127685546875, 2411.5576171875, 1975.911865234375, 1877.8106689453125, 1831.109619140625, 1726.1973876953125, 1701.7943115234375, 1171.7718505859375, 1154.070068359375, 1114.433837890625, 1052.5352783203125, 1012.8605346679688, 998.733154296875, 985.0899047851562, 877.80029296875, 872.2382202148438, 850.86767578125, 846.0451049804688, 731.6151733398438, 722.6948852539062, 2542.841064453125, 5287.5888671875, 14411.447265625, 5634.3525390625, 3896.01220703125, 11624.150390625, 3444.57958984375, 2889.064697265625, 8723.546875, 7374.3056640625, 5786.97119140625, 16243.4091796875, 4502.369140625, 17527.765625, 57466.62109375, 30443.447265625, 6081.8984375, 21177.4921875, 20924.69921875, 32877.96484375, 44823.02734375, 36513.859375, 22854.703125, 14424.1611328125, 8092.2451171875, 39339.4453125, 20495.40625, 62472.79296875, 40079.5390625, 8624.8466796875, 8336.298828125, 5767.1748046875, 3730.830810546875, 3468.1474609375, 2829.8447265625, 2587.075439453125, 2546.54833984375, 2508.474853515625, 2841.072509765625, 1519.93408203125, 1495.18701171875, 1493.865478515625, 1443.572509765625, 1443.034912109375, 1421.5360107421875, 1354.1630859375, 1270.1806640625, 1255.4088134765625, 1231.4495849609375, 1211.6029052734375, 1201.6124267578125, 1197.768310546875, 1191.6185302734375, 1178.957275390625, 1161.9241943359375, 1075.8837890625, 977.0737915039062, 919.5938720703125, 892.2479858398438, 12036.76953125, 2692.1923828125, 5349.5556640625, 4248.078125, 7317.1591796875, 21177.4921875, 6758.0126953125, 12183.26171875, 4777.126953125, 2737.64599609375, 4277.76171875, 142278.609375, 17527.765625, 17067.54296875, 2917.65771484375, 5315.109375, 6747.3935546875, 27127.966796875], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -3.047300100326538, -4.601799964904785, -4.679500102996826, -4.781300067901611, -5.373199939727783, -5.5802001953125, -5.733399868011475, -5.74399995803833, -5.84689998626709, -5.895400047302246, -5.90910005569458, -6.008800029754639, -6.139100074768066, -6.154600143432617, -6.164400100708008, -6.2017998695373535, -6.258200168609619, -6.258800029754639, -6.287300109863281, -6.313499927520752, -6.545499801635742, -7.058700084686279, -7.059800148010254, -7.150599956512451, -7.162399768829346, -7.182499885559082, -7.212900161743164, -7.212600231170654, -7.216899871826172, -7.3018999099731445, -3.7994000911712646, -5.2118000984191895, -5.480400085449219, -4.360000133514404, -5.315499782562256, -3.7116000652313232, -4.5696001052856445, -6.345699787139893, -5.612599849700928, -3.321199893951416, -3.736299991607666, -3.586699962615967, -3.5360000133514404, -4.045599937438965, -5.546000003814697, -5.526700019836426, -4.053199768066406, -5.219799995422363, -4.367499828338623, -3.9302000999450684, -4.448500156402588, -4.485199928283691, -3.919300079345703, -4.530600070953369, -4.382800102233887, -4.256199836730957, -4.6528000831604, -3.9593000411987305, -4.920100212097168, -4.6682000160217285, -4.645500183105469, -4.624499797821045, -4.982600212097168, -5.001800060272217, -3.680500030517578, -4.400400161743164, -4.621799945831299, -4.96019983291626, -5.085899829864502, -5.16349983215332, -5.236199855804443, -5.2845001220703125, -5.745500087738037, -5.891900062561035, -5.953400135040283, -6.001299858093262, -6.055600166320801, -6.2789998054504395, -6.325099945068359, -6.366799831390381, -6.391900062561035, -6.406700134277344, -6.490900039672852, -6.552499771118164, -6.633500099182129, -6.697400093078613, -6.700200080871582, -6.718100070953369, -6.723899841308594, -6.1350998878479, -6.735899925231934, -6.761199951171875, -6.779200077056885, -6.785399913787842, -5.993500232696533, -4.075799942016602, -6.117700099945068, -5.009300231933594, -4.823599815368652, -5.145500183105469, -4.579800128936768, -5.86870002746582, -5.133500099182129, -3.784600019454956, -5.141600131988525, -4.946499824523926, -5.641200065612793, -4.905399799346924, -5.3790998458862305, -4.902299880981445, -2.9433999061584473, -4.603499889373779, -4.57859992980957, -4.996300220489502, -3.733099937438965, -4.064199924468994, -4.283999919891357, -4.976600170135498, -4.182300090789795, -5.236199855804443, -4.571199893951416, -4.583000183105469, -4.872600078582764, -4.8719000816345215, -4.949399948120117, -5.0619001388549805, -5.068699836730957, -5.110199928283691, -3.9075000286102295, -4.6875, -4.811600208282471, -5.038700103759766, -5.110899925231934, -5.32919979095459, -5.387599945068359, -5.426000118255615, -5.525899887084961, -5.584799766540527, -5.639400005340576, -5.6682000160217285, -5.680200099945068, -5.692800045013428, -5.7027997970581055, -5.725299835205078, -5.774499893188477, -5.782299995422363, -5.860899925231934, -5.933499813079834, -6.0229997634887695, -6.035299777984619, -6.062900066375732, -6.077199935913086, -6.09250020980835, -6.128699779510498, -6.200099945068359, -6.324900150299072, -6.340700149536133, -6.381800174713135, -4.589200019836426, -4.393199920654297, -2.746299982070923, -4.401299953460693, -5.057700157165527, -3.6554999351501465, -4.311399936676025, -4.557199954986572, -2.8513998985290527, -4.212100028991699, -3.872999906539917, -5.151299953460693, -4.4766998291015625, -4.7017998695373535, -4.570000171661377, -4.5894999504089355, -5.153299808502197, -4.651800155639648, -4.386899948120117, -4.7555999755859375, -5.382500171661377, -5.158299922943115, -4.763899803161621, -5.045100212097168, -4.801400184631348, -5.0640997886657715, -5.119699954986572, -3.656399965286255, -4.343400001525879, -4.650400161743164, -4.792799949645996, -4.944499969482422, -4.961900234222412, -5.0100998878479, -5.257599830627441, -5.380000114440918, -5.386099815368652, -5.533199787139893, -5.551300048828125, -5.724400043487549, -5.7530999183654785, -5.759799957275391, -5.760799884796143, -5.780399799346924, -5.950099945068359, -5.957200050354004, -5.99429988861084, -6.021699905395508, -6.028500080108643, -6.109300136566162, -6.125500202178955, -6.245999813079834, -6.287700176239014, -6.298799991607666, -6.32889986038208, -6.4359002113342285, -6.539400100708008, -3.3575000762939453, -4.436200141906738, -2.73799991607666, -4.224999904632568, -5.44290018081665, -3.8229000568389893, -3.8136000633239746, -4.371799945831299, -4.593599796295166, -4.694200038909912, -4.525700092315674, -4.422699928283691, -5.015999794006348, -4.981400012969971, -4.947299957275391, -4.7444000244140625, -4.091100215911865, -3.7290000915527344, -4.6528000831604, -4.748600006103516, -4.954599857330322, -4.054299831390381, -4.827700138092041, -4.733799934387207, -4.674200057983398, -3.984800100326538, -4.513700008392334, -4.799799919128418, -4.815700054168701, -4.841700077056885, -4.884799957275391, -2.765399932861328, -3.3213999271392822, -3.5129001140594482, -3.7195000648498535, -4.389699935913086, -5.2270002365112305, -5.4070000648498535, -5.696400165557861, -5.9653000831604, -6.002299785614014, -6.095200061798096, -6.10099983215332, -6.165900230407715, -6.1732001304626465, -6.235599994659424, -6.2378997802734375, -6.258699893951416, -6.260700225830078, -6.418799877166748, -6.448299884796143, -6.46120023727417, -6.470099925994873, -6.504899978637695, -6.593400001525879, -6.611299991607666, -6.692399978637695, -6.713200092315674, -6.714600086212158, -6.798299789428711, -6.851399898529053, -2.430299997329712, -4.894499778747559, -3.735100030899048, -4.089799880981445, -4.7017998695373535, -5.032800197601318, -4.224599838256836, -5.047100067138672, -3.5246999263763428, -5.545199871063232, -4.926799774169922, -5.342700004577637, -3.853800058364868, -4.837399959564209, -5.530300140380859, -4.662300109863281, -5.312399864196777, -5.708899974822998, -4.334799766540527, -3.948899984359741, -5.3856000900268555, -5.355299949645996, -4.684500217437744, -4.46619987487793, -3.216900110244751, -4.333199977874756, -4.724299907684326, -4.840400218963623, -4.985099792480469, -5.293499946594238, -5.224599838256836, -5.201700210571289, -5.2195000648498535, -2.6120998859405518, -3.492500066757202, -3.5327000617980957, -3.6719000339508057, -3.9047000408172607, -4.191100120544434, -4.730599880218506, -5.086900234222412, -5.139500141143799, -5.30649995803833, -5.323500156402588, -5.5152997970581055, -5.714600086212158, -5.765500068664551, -5.7906999588012695, -5.849699974060059, -5.863999843597412, -6.237400054931641, -6.252600193023682, -6.287600040435791, -6.344799995422363, -6.383200168609619, -6.397299766540527, -6.411099910736084, -6.526500225067139, -6.532800197601318, -6.557700157165527, -6.563399791717529, -6.708799839019775, -6.721099853515625, -5.4654998779296875, -4.825799942016602, -3.8952999114990234, -4.840700149536133, -5.178599834442139, -4.282299995422363, -5.372499942779541, -5.527100086212158, -4.632900238037109, -4.795899868011475, -5.008200168609619, -4.260799884796143, -5.223899841308594, -4.2332000732421875, -3.451200008392334, -4.002699851989746, -5.098400115966797, -4.431399822235107, -4.508299827575684, -4.327499866485596, -4.228799819946289, -4.3302001953125, -4.679599761962891, -4.890699863433838, -5.051300048828125, -4.774400234222412, -4.965000152587891, -5.000199794769287, -5.080100059509277, -3.649399995803833, -3.6833999156951904, -4.0518999099731445, -4.487599849700928, -4.5605998039245605, -4.763999938964844, -4.853799819946289, -4.86959981918335, -4.8846001625061035, -4.7600998878479, -5.385799884796143, -5.402299880981445, -5.403200149536133, -5.437399864196777, -5.43779993057251, -5.4527997970581055, -5.501399993896484, -5.565499782562256, -5.577199935913086, -5.596399784088135, -5.61269998550415, -5.620999813079834, -5.624199867248535, -5.62939977645874, -5.639999866485596, -5.654600143432617, -5.731599807739258, -5.828000068664551, -5.888700008392334, -5.918900012969971, -3.5471999645233154, -4.967800140380859, -4.3983001708984375, -4.625999927520752, -4.271599769592285, -3.8118999004364014, -4.625199794769287, -4.537600040435791, -5.038700103759766, -5.276899814605713, -5.1143999099731445, -3.8369998931884766, -4.650899887084961, -4.814199924468994, -5.303400039672852, -5.219399929046631, -5.297599792480469, -5.397299766540527], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.6088000535964966, 1.6087000370025635, 1.6087000370025635, 1.6087000370025635, 1.6086000204086304, 1.6086000204086304, 1.6086000204086304, 1.6085000038146973, 1.6085000038146973, 1.6085000038146973, 1.6085000038146973, 1.6085000038146973, 1.6083999872207642, 1.6083999872207642, 1.6083999872207642, 1.6083999872207642, 1.6083999872207642, 1.6083999872207642, 1.608299970626831, 1.608299970626831, 1.608199954032898, 1.607800006866455, 1.607800006866455, 1.607699990272522, 1.607699990272522, 1.6075999736785889, 1.6075999736785889, 1.6075999736785889, 1.6075999736785889, 1.6074999570846558, 1.4709999561309814, 1.5295000076293945, 1.524899959564209, 1.4401999711990356, 1.500100016593933, 1.3358999490737915, 1.4081000089645386, 1.5404000282287598, 1.4502999782562256, 1.1686999797821045, 1.2073999643325806, 1.1154999732971191, 1.0978000164031982, 1.0902999639511108, 1.4249000549316406, 1.4127999544143677, 0.9674000144004822, 1.3181999921798706, 1.0103000402450562, 0.8341000080108643, 0.9678000211715698, 0.965399980545044, 0.4659999907016754, 0.7433000206947327, 0.5967000126838684, 0.4893999993801117, 0.7427999973297119, -0.4805999994277954, 0.6791999936103821, 0.31450000405311584, 0.19329999387264252, -0.32269999384880066, 0.397599995136261, 0.3370000123977661, 1.844599962234497, 1.844599962234497, 1.844499945640564, 1.844499945640564, 1.844499945640564, 1.844499945640564, 1.8444000482559204, 1.8444000482559204, 1.8443000316619873, 1.8442000150680542, 1.8442000150680542, 1.8442000150680542, 1.8442000150680542, 1.843999981880188, 1.843999981880188, 1.843999981880188, 1.843999981880188, 1.843999981880188, 1.8438999652862549, 1.8437999486923218, 1.8437999486923218, 1.8437000513076782, 1.8437000513076782, 1.8437000513076782, 1.8437000513076782, 1.8437000513076782, 1.8437000513076782, 1.8437000513076782, 1.8436000347137451, 1.8436000347137451, 1.8310999870300293, 1.7383999824523926, 1.8152999877929688, 1.7470999956130981, 1.6841000318527222, 1.6793999671936035, 1.5967999696731567, 1.7197999954223633, 1.5966999530792236, 1.3421000242233276, 1.5853999853134155, 1.5217000246047974, 1.6640000343322754, 1.4646999835968018, 1.5332000255584717, 1.3615000247955322, 0.5353000164031982, 1.1780999898910522, 1.121999979019165, 1.2934999465942383, 0.5814999938011169, 0.7001000046730042, 0.7343000173568726, 1.1848000288009644, 0.5199000239372253, 1.3325999975204468, 0.4115000069141388, 0.39640000462532043, 0.5101000070571899, 0.3328000009059906, 0.6561999917030334, 0.5374000072479248, -0.22990000247955322, 0.41370001435279846, 1.8794000148773193, 1.8794000148773193, 1.8792999982833862, 1.8792999982833862, 1.8792999982833862, 1.8791999816894531, 1.8791999816894531, 1.8791999816894531, 1.8791999816894531, 1.8791999816894531, 1.87909996509552, 1.87909996509552, 1.87909996509552, 1.87909996509552, 1.87909996509552, 1.87909996509552, 1.87909996509552, 1.87909996509552, 1.87909996509552, 1.878999948501587, 1.878999948501587, 1.878999948501587, 1.878999948501587, 1.878999948501587, 1.878999948501587, 1.8789000511169434, 1.8789000511169434, 1.8788000345230103, 1.8788000345230103, 1.8788000345230103, 1.8152999877929688, 1.7372000217437744, 1.5555000305175781, 1.6994999647140503, 1.7383999824523926, 1.3628000020980835, 1.4562000036239624, 1.3736000061035156, 0.6273000240325928, 1.0618000030517578, 0.8726000189781189, 1.4341000318527222, 0.8866000175476074, 1.0551999807357788, 0.8126999735832214, 0.7907000184059143, 1.3224999904632568, 0.7317000031471252, 0.24690000712871552, 0.5516999959945679, 1.4707000255584717, 1.0120999813079834, 0.07490000128746033, 0.6036999821662903, -0.49639999866485596, -0.08470000326633453, 0.2581000030040741, 1.9089000225067139, 1.9088000059127808, 1.9088000059127808, 1.9088000059127808, 1.9088000059127808, 1.9088000059127808, 1.9086999893188477, 1.9086999893188477, 1.9086999893188477, 1.9086999893188477, 1.9085999727249146, 1.9085999727249146, 1.9085999727249146, 1.9084999561309814, 1.9084999561309814, 1.9084999561309814, 1.9084999561309814, 1.9084999561309814, 1.9084999561309814, 1.908400058746338, 1.908400058746338, 1.908400058746338, 1.908400058746338, 1.908400058746338, 1.9083000421524048, 1.9083000421524048, 1.9083000421524048, 1.9082000255584717, 1.9082000255584717, 1.9081000089645386, 1.9048999547958374, 1.7790000438690186, 1.5765999555587769, 1.670699954032898, 1.7907999753952026, 1.5159000158309937, 1.465399980545044, 1.5647000074386597, 1.6055999994277954, 1.6030999422073364, 1.5604000091552734, 1.5235999822616577, 1.5647000074386597, 1.517199993133545, 1.4465999603271484, 1.2978999614715576, 0.8916000127792358, 0.6563000082969666, 1.2237999439239502, 1.25409996509552, 1.4139000177383423, 0.43560001254081726, 1.2757999897003174, 1.1339999437332153, 0.9592000246047974, -0.5060999989509583, 0.32510000467300415, 0.7240999937057495, 0.6348999738693237, 0.13779999315738678, -0.1826000064611435, 1.9723000526428223, 1.9723000526428223, 1.9723000526428223, 1.9723000526428223, 1.9722000360488892, 1.972100019454956, 1.972000002861023, 1.9718999862670898, 1.9717999696731567, 1.9717999696731567, 1.9716999530792236, 1.9716999530792236, 1.9716999530792236, 1.9716999530792236, 1.97160005569458, 1.97160005569458, 1.97160005569458, 1.97160005569458, 1.971500039100647, 1.971500039100647, 1.971500039100647, 1.971500039100647, 1.9714000225067139, 1.9713000059127808, 1.9713000059127808, 1.9711999893188477, 1.9711999893188477, 1.9711999893188477, 1.9710999727249146, 1.9710999727249146, 1.8747999668121338, 1.8985999822616577, 1.8287999629974365, 1.8249000310897827, 1.8575999736785889, 1.8774000406265259, 1.8075000047683716, 1.8680000305175781, 1.7080999612808228, 1.8624000549316406, 1.7523000240325928, 1.7963999509811401, 1.5095000267028809, 1.6899000406265259, 1.8243999481201172, 1.5989999771118164, 1.753499984741211, 1.84660005569458, 1.4536999464035034, 1.2558000087738037, 1.733199954032898, 1.7210999727249146, 1.4306000471115112, 1.139299988746643, 0.26170000433921814, 0.9456999897956848, 0.6559000015258789, 0.6834999918937683, 0.14159999787807465, 1.4556000232696533, 0.5322999954223633, -0.4560999870300293, -0.1988999992609024, 2.041300058364868, 2.0411999225616455, 2.0411999225616455, 2.0411999225616455, 2.0411999225616455, 2.0411999225616455, 2.041100025177002, 2.041100025177002, 2.041100025177002, 2.0409998893737793, 2.0409998893737793, 2.0408999919891357, 2.0408999919891357, 2.040800094604492, 2.040800094604492, 2.040800094604492, 2.040800094604492, 2.040600061416626, 2.040600061416626, 2.0404999256134033, 2.0404999256134033, 2.0404999256134033, 2.0404999256134033, 2.0404000282287598, 2.040299892425537, 2.040299892425537, 2.040299892425537, 2.040299892425537, 2.0401999950408936, 2.04010009765625, 2.0376999378204346, 1.9453999996185303, 1.8732000589370728, 1.8667999505996704, 1.8978999853134155, 1.7010999917984009, 1.8272000551223755, 1.8485000133514404, 1.6375000476837158, 1.6426000595092773, 1.672700047492981, 1.3880000114440918, 1.7079999446868896, 1.339400053024292, 0.9340000152587891, 1.017899990081787, 1.5326999425888062, 0.9520999789237976, 0.8873000144958496, 0.6161999702453613, 0.4050000011920929, 0.5085999965667725, 0.6276999711990356, 0.8769000172615051, 1.2942999601364136, -0.010200000368058681, 0.4512999951839447, -0.6984999775886536, -0.3345000147819519, 2.6324000358581543, 2.6324000358581543, 2.6324000358581543, 2.6322999000549316, 2.6322999000549316, 2.632200002670288, 2.632200002670288, 2.632200002670288, 2.632200002670288, 2.632200002670288, 2.631999969482422, 2.631999969482422, 2.631999969482422, 2.6319000720977783, 2.6319000720977783, 2.6319000720977783, 2.6319000720977783, 2.6319000720977783, 2.6317999362945557, 2.6317999362945557, 2.6317999362945557, 2.6317999362945557, 2.6317999362945557, 2.6317999362945557, 2.6317999362945557, 2.6317999362945557, 2.631700038909912, 2.631700038909912, 2.6315999031066895, 2.6315999031066895, 2.401400089263916, 2.478300094604492, 2.3612000942230225, 2.364000082015991, 2.1745998859405518, 1.5715999603271484, 1.9005000591278076, 1.398800015449524, 1.833899974822998, 2.1524999141693115, 1.8686000108718872, -0.35830000042915344, 0.9218000173568726, 0.785099983215332, 2.062299966812134, 1.5464999675750732, 1.229699969291687, -0.2614000141620636]}, \"token.table\": {\"Topic\": [7, 3, 6, 4, 5, 6, 1, 2, 4, 6, 6, 4, 1, 2, 3, 4, 2, 6, 7, 7, 1, 1, 3, 1, 3, 1, 6, 1, 1, 3, 5, 6, 2, 1, 4, 1, 2, 4, 5, 6, 7, 1, 2, 4, 1, 2, 3, 5, 6, 3, 6, 1, 2, 4, 5, 5, 5, 5, 2, 5, 6, 6, 1, 2, 7, 7, 3, 5, 4, 7, 4, 5, 1, 2, 2, 4, 4, 6, 1, 2, 4, 1, 5, 6, 2, 6, 3, 7, 6, 7, 4, 6, 2, 4, 6, 6, 7, 2, 1, 3, 5, 6, 7, 6, 4, 3, 2, 1, 2, 3, 4, 5, 6, 1, 5, 6, 3, 3, 5, 5, 7, 1, 2, 3, 4, 5, 6, 7, 5, 7, 5, 1, 3, 1, 1, 4, 5, 2, 7, 3, 7, 3, 6, 3, 7, 7, 1, 1, 3, 4, 6, 1, 5, 4, 5, 6, 7, 7, 3, 1, 2, 3, 2, 7, 7, 7, 1, 4, 6, 4, 2, 5, 5, 1, 3, 5, 6, 2, 4, 7, 2, 3, 6, 7, 1, 3, 1, 2, 1, 4, 5, 4, 5, 5, 4, 7, 6, 1, 2, 3, 4, 1, 2, 3, 5, 6, 1, 2, 4, 6, 3, 4, 7, 3, 7, 2, 5, 1, 4, 5, 2, 2, 3, 6, 2, 5, 6, 1, 2, 3, 4, 6, 1, 2, 4, 6, 6, 1, 3, 1, 2, 3, 4, 6, 7, 5, 3, 1, 2, 4, 5, 6, 1, 2, 3, 4, 5, 2, 3, 2, 2, 1, 2, 4, 6, 2, 3, 1, 2, 3, 4, 5, 6, 1, 1, 4, 5, 2, 3, 5, 4, 3, 7, 3, 6, 2, 3, 4, 3, 3, 4, 4, 4, 1, 6, 7, 1, 2, 3, 4, 5, 6, 7, 6, 7, 4, 7, 2, 1, 2, 4, 5, 6, 4, 7, 1, 3, 4, 5, 6, 2, 5, 3, 4, 5, 4, 5, 1, 5, 3, 7, 7, 1, 2, 4, 1, 1, 2, 4, 5, 6, 3, 5, 2, 3, 5, 1, 6, 7, 1, 2, 3, 4, 5, 6, 6, 1, 3, 4, 5, 1, 1, 1, 2, 3, 5, 4, 5, 7, 1, 2, 1, 2, 4, 6, 4, 6, 5, 7, 5, 4, 7, 1, 2, 3, 4, 5, 6, 7, 5, 1, 2, 3, 4, 5, 6, 7, 4, 4, 1, 2, 4, 6, 1, 6, 1, 2, 3, 6, 4, 1, 2, 3, 4, 5, 6, 6, 1, 4, 7, 3, 6, 4, 5, 6, 7, 3, 6, 7, 2, 7, 7, 5, 5, 3, 4, 5, 7, 2, 5, 1, 3, 6, 1, 6, 3, 7, 5, 6, 4, 4, 5, 6, 2, 6, 2, 6, 1, 1, 3, 5, 5, 1, 2, 3, 4, 5, 6, 7, 7, 6, 3, 1, 6, 3, 6, 7, 2, 1, 2, 4, 5, 6, 5, 1, 2, 3, 4, 6, 7, 2, 3, 2, 3, 4, 3, 4, 1, 6, 1, 2, 3, 4, 5, 6, 2, 4, 4, 1, 2, 4, 2, 5, 7, 1, 6, 3, 6, 5, 5, 1, 1, 3, 2, 7, 2, 3, 4, 6, 1, 4, 6, 2, 1, 3, 5, 6, 1, 2, 3, 4, 5, 6, 3, 6, 7, 4, 7, 1, 5, 4, 5, 2, 7, 2, 7, 3, 7, 5, 6, 6, 6, 2, 6, 3, 4, 3, 2, 7, 6, 3, 6, 2, 4, 2, 1, 3, 4, 1, 4, 7, 5, 6, 2, 4, 1, 3, 2, 2, 2, 3, 1, 2, 3, 4, 6, 7, 3, 1, 4, 5, 6, 2, 6, 1, 2, 3, 5, 6, 7, 2, 2, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 6, 5, 7, 6, 1, 2, 3, 4, 5, 6, 2, 5, 7, 4, 1, 5, 2, 4, 2, 6, 4, 6, 4, 1, 1, 2, 3, 4, 6, 6, 1, 4, 5, 3, 5, 6, 7, 1, 4, 6, 3, 1, 2, 3, 5, 6, 1, 2, 3, 4, 6, 1, 3, 4, 6, 1, 6, 1, 2, 3, 4, 5], \"Freq\": [0.9994809031486511, 0.3081059157848358, 0.6917262673377991, 0.9992668032646179, 0.9988343119621277, 0.9999160766601562, 0.3352603018283844, 0.044304464012384415, 0.5040502548217773, 0.11636687070131302, 0.9997687935829163, 0.9999153017997742, 0.1585497409105301, 0.6838407516479492, 0.13474196195602417, 0.02279469184577465, 0.18263866007328033, 0.1983455866575241, 0.6187797784805298, 0.9995843172073364, 0.9980747103691101, 0.9995555281639099, 0.9997406005859375, 0.8181297183036804, 0.18184462189674377, 0.9337149858474731, 0.06574645638465881, 0.9993303418159485, 0.9983282089233398, 0.1016530841588974, 0.6884015202522278, 0.20978015661239624, 0.9997327923774719, 0.3240211606025696, 0.6758361458778381, 0.595400333404541, 0.16090406477451324, 0.055662114173173904, 0.07847989350557327, 0.05418762192130089, 0.05536721646785736, 0.21193377673625946, 0.1782975047826767, 0.6096256971359253, 0.0013808108633384109, 0.0015838713152334094, 0.10989630222320557, 0.7677714824676514, 0.11935891956090927, 0.9999173283576965, 0.9995903968811035, 0.06372629851102829, 0.14191150665283203, 0.006693939212709665, 0.7874749898910522, 0.9988486766815186, 0.9992669224739075, 0.9995827078819275, 0.73241126537323, 0.2674400806427002, 0.9989802241325378, 0.9994914531707764, 0.9988133907318115, 0.8992354273796082, 0.10075446963310242, 0.9998441934585571, 0.37046509981155396, 0.6294575333595276, 0.7087593078613281, 0.29121923446655273, 0.9995677471160889, 0.9994538426399231, 0.21947337687015533, 0.7804103493690491, 0.9995326995849609, 0.9995428323745728, 0.9998645782470703, 0.9992659091949463, 0.610610842704773, 0.26588496565818787, 0.12349352240562439, 0.5265501141548157, 0.11404753476381302, 0.35938769578933716, 0.9987711310386658, 0.9995682835578918, 0.9995748400688171, 0.9998106956481934, 0.9999229311943054, 0.9993585348129272, 0.9998658895492554, 0.9988936185836792, 0.7804877758026123, 0.08432064950466156, 0.13514262437820435, 0.9085426330566406, 0.09134598076343536, 0.998595118522644, 0.215884730219841, 0.08231283724308014, 0.0009492419194430113, 0.6712496280670166, 0.029562104493379593, 0.9996107220649719, 0.9996713399887085, 0.9988898634910583, 0.9990870952606201, 0.08551688492298126, 0.043395571410655975, 0.09634807705879211, 0.1511411815881729, 0.5952909588813782, 0.02831684984266758, 0.8321013450622559, 0.16789832711219788, 0.999837338924408, 0.999655544757843, 0.9997135996818542, 0.9996089339256287, 0.9999850392341614, 0.9994903206825256, 0.39472582936286926, 0.2705720365047455, 0.025838516652584076, 0.06433263421058655, 5.8590740081854165e-05, 0.0868900716304779, 0.15760909020900726, 0.7778879404067993, 0.22199706733226776, 0.9997610449790955, 0.1325368881225586, 0.8673692345619202, 0.9994665384292603, 0.1434897929430008, 0.052824556827545166, 0.8035427927970886, 0.9999246001243591, 0.9990704655647278, 0.9995977878570557, 0.9997014999389648, 0.6405293941497803, 0.35921794176101685, 0.8683106303215027, 0.13146820664405823, 0.9996225237846375, 0.9993326663970947, 0.4208340644836426, 0.44144201278686523, 0.028690345585346222, 0.10904870182275772, 0.9998593926429749, 0.9994434714317322, 0.705777108669281, 0.2942088544368744, 0.5189395546913147, 0.48091059923171997, 0.999385416507721, 0.9995260834693909, 0.8448126316070557, 0.15492409467697144, 0.00021487391495611519, 0.9996323585510254, 0.9999018311500549, 0.9991880059242249, 0.9995023608207703, 0.2803281843662262, 0.6750363707542419, 0.04461408406496048, 0.9993090629577637, 0.9987332224845886, 0.9999263286590576, 0.9992252588272095, 0.9997473955154419, 0.9996888637542725, 0.8386110067367554, 0.1612188071012497, 0.261543869972229, 0.7384077310562134, 0.9992045760154724, 0.9997495412826538, 0.09790828078985214, 0.8453002572059631, 0.056760434061288834, 0.999853789806366, 0.9998293519020081, 0.9998868703842163, 0.9997901320457458, 0.9996535181999207, 0.6417394876480103, 0.3582325875759125, 0.11767937242984772, 0.8817665576934814, 0.9994773268699646, 0.9999749064445496, 0.9991785287857056, 0.999072790145874, 0.17450855672359467, 0.30847471952438354, 0.056253526359796524, 0.4607577621936798, 0.09650581330060959, 0.22049446403980255, 0.07628855854272842, 0.48845210671424866, 0.11822357028722763, 0.14804835617542267, 0.1368219405412674, 0.51948481798172, 0.1955852061510086, 0.4948849678039551, 0.03903910890221596, 0.4658978581428528, 0.9996069669723511, 0.9996229410171509, 0.9070043563842773, 0.09280627965927124, 0.2746734619140625, 0.14347001910209656, 0.5817307233810425, 0.9997656345367432, 0.20038896799087524, 0.27919015288352966, 0.5203341245651245, 0.9989546537399292, 0.9992204308509827, 0.99876469373703, 0.08682560175657272, 0.5992820262908936, 0.05716276541352272, 0.03383417800068855, 0.2229347825050354, 0.31891557574272156, 0.06485503911972046, 0.2857484817504883, 0.33047008514404297, 0.9999535083770752, 0.9194843769073486, 0.08030848950147629, 0.5267521739006042, 0.0015125341014936566, 0.12256404757499695, 0.12168580293655396, 0.20394814014434814, 0.02356625720858574, 0.999642014503479, 0.9997686147689819, 0.6439335346221924, 0.06988441199064255, 0.22916753590106964, 0.00028981646755710244, 0.056726742535829544, 0.12584355473518372, 0.5134979486465454, 0.21428555250167847, 0.047033146023750305, 0.09940937161445618, 0.6168156266212463, 0.3830474019050598, 0.9999719262123108, 0.998932421207428, 0.17651128768920898, 0.06146690249443054, 0.7365430593490601, 0.025552334263920784, 0.9713678956031799, 0.02840963937342167, 0.5496351718902588, 0.031972456723451614, 0.19760951399803162, 0.02915550209581852, 0.0969972088932991, 0.09455584734678268, 0.9997212290763855, 0.896898627281189, 0.10281907021999359, 0.9992775917053223, 0.18820379674434662, 0.572916567325592, 0.23873868584632874, 0.9992179870605469, 0.9995247721672058, 0.9992828369140625, 0.3985597491264343, 0.6012924909591675, 0.1035144180059433, 0.8352742791175842, 0.06114122271537781, 0.9997724890708923, 0.9998326301574707, 0.9995028972625732, 0.999623715877533, 0.9992168545722961, 0.32354381680488586, 0.49567070603370667, 0.1807418018579483, 0.3264508545398712, 0.03375787287950516, 0.3653485178947449, 0.09308989346027374, 0.08817466348409653, 0.09294018894433975, 0.00019960309145972133, 0.8244882822036743, 0.17514318227767944, 0.14263467490673065, 0.8569223880767822, 0.9989596605300903, 0.07628758251667023, 0.23907789587974548, 0.3058023750782013, 0.2755916118621826, 0.10323818773031235, 0.9994174838066101, 0.9996691346168518, 0.23677542805671692, 0.4200352430343628, 0.011304652318358421, 0.1942533403635025, 0.13762636482715607, 0.10834081470966339, 0.891516387462616, 0.999906599521637, 0.09894159436225891, 0.900958240032196, 0.13701823353767395, 0.8629096746444702, 0.13364119827747345, 0.8663206696510315, 0.9378596544265747, 0.061999667435884476, 0.9996033906936646, 0.12255813926458359, 0.247580423951149, 0.6297802329063416, 0.9997421503067017, 0.15736162662506104, 0.30470019578933716, 0.0775311067700386, 0.4347637891769409, 0.025647172704339027, 0.09294106811285019, 0.9070547223091125, 0.32946065068244934, 0.5964899063110352, 0.07406555861234665, 0.9995587468147278, 0.9965231418609619, 0.003146087285131216, 0.3634237051010132, 0.23496922850608826, 0.14027543365955353, 0.17012730240821838, 0.005674062296748161, 0.08548920601606369, 0.9985803961753845, 0.2978553771972656, 0.33663448691368103, 0.09741833806037903, 0.2680651545524597, 0.9993818998336792, 0.9996218085289001, 0.011804798617959023, 0.5763313174247742, 0.27770495414733887, 0.1341773122549057, 0.9996713995933533, 0.9990761876106262, 0.9996349215507507, 0.8220125436782837, 0.17791993916034698, 0.37632524967193604, 0.001551292254589498, 0.5427697896957397, 0.07929841428995132, 0.8885001540184021, 0.11113760620355606, 0.9994179606437683, 0.9992061257362366, 0.9999741911888123, 0.9993368983268738, 0.9994206428527832, 0.4206034243106842, 0.08707413077354431, 0.13701510429382324, 0.016439901664853096, 0.006260544061660767, 0.3153689205646515, 0.01725233905017376, 0.9987993240356445, 0.08953725546598434, 0.4854203164577484, 0.18341846764087677, 0.09057461470365524, 0.04084610566496849, 0.057573556900024414, 0.05264609307050705, 0.9999383091926575, 0.9992594718933105, 0.06644081324338913, 0.16274091601371765, 0.7088062763214111, 0.06190720573067665, 0.28827914595603943, 0.711621880531311, 0.07451578229665756, 0.11578986793756485, 0.33587712049484253, 0.4737869203090668, 0.9992862343788147, 0.07906562834978104, 0.7240232825279236, 0.0009778435342013836, 0.06369952112436295, 0.12390673905611038, 0.008381515741348267, 0.9999434351921082, 0.18069632351398468, 0.0256713405251503, 0.7935684323310852, 0.9995741248130798, 0.9999743103981018, 0.07452018558979034, 0.8024719953536987, 0.12282031029462814, 0.9986013174057007, 0.049481578171253204, 0.6127813458442688, 0.3375283181667328, 0.23540057241916656, 0.764581024646759, 0.9997846484184265, 0.9997177124023438, 0.9990364909172058, 0.9997214674949646, 0.9989803433418274, 0.7539207339286804, 0.24587272107601166, 0.8476356863975525, 0.15208344161510468, 0.8532868027687073, 0.14432448148727417, 0.0020256065763533115, 0.1924763172864914, 0.8073554039001465, 0.999587893486023, 0.9997773170471191, 0.9094153046607971, 0.09041987359523773, 0.999780535697937, 0.10400897264480591, 0.8960498571395874, 0.99996417760849, 0.999613344669342, 0.9991503953933716, 0.1599119007587433, 0.8398480415344238, 0.999433696269989, 0.9991798996925354, 0.9996896982192993, 0.9999425411224365, 0.9996021389961243, 0.12375718355178833, 0.269991397857666, 0.28586870431900024, 0.08936691284179688, 0.1807650476694107, 7.028463187452871e-06, 0.05024648457765579, 0.9989010095596313, 0.9991591572761536, 0.9994664788246155, 0.9995554685592651, 0.9990882873535156, 0.6643996238708496, 0.06693272292613983, 0.26855215430259705, 0.9998676776885986, 0.46080973744392395, 0.31835731863975525, 0.04890765622258186, 0.043366141617298126, 0.1285478174686432, 0.999641478061676, 0.2061266154050827, 0.03821830078959465, 0.07148956507444382, 0.5308851599693298, 0.12736199796199799, 0.02580220252275467, 0.8345815539360046, 0.1651742309331894, 0.9865094423294067, 0.013016067445278168, 0.9996243715286255, 0.9998900890350342, 0.9999299049377441, 0.9999546408653259, 0.9999388456344604, 0.08449870347976685, 0.5169634819030762, 0.17907145619392395, 0.15203598141670227, 0.00030838942620903254, 0.06712609529495239, 0.9988014698028564, 0.999915599822998, 0.999839723110199, 0.9993911981582642, 0.9992308020591736, 0.9997665882110596, 0.11066339910030365, 0.12692642211914062, 0.7623063325881958, 0.8712154626846313, 0.12877224385738373, 0.9998066425323486, 0.9995332360267639, 0.9994956851005554, 0.9992090463638306, 0.9996446967124939, 0.9237763285636902, 0.07618584483861923, 0.3672190308570862, 0.6326225399971008, 0.00027731250156648457, 0.6548734307289124, 0.032722871750593185, 0.3121151924133301, 0.6693236827850342, 0.09018198400735855, 0.24046500027179718, 0.9996840357780457, 0.9980877041816711, 0.9993657469749451, 0.862427830696106, 0.1372968852519989, 0.21514171361923218, 0.060687728226184845, 0.2650657892227173, 0.08947829902172089, 0.12640723586082458, 0.2432759702205658, 0.31736525893211365, 0.33648931980133057, 0.34612220525741577, 0.9996750354766846, 0.9993541836738586, 0.9999489188194275, 0.9999609589576721, 0.07094614207744598, 0.9288725256919861, 0.8515909910202026, 0.14822915196418762, 0.8827148675918579, 0.11692438274621964, 0.9995494484901428, 0.9991410970687866, 0.9983233213424683, 0.9996139407157898, 0.9996604919433594, 0.9995384812355042, 0.7715752720832825, 0.22836022078990936, 0.004015966318547726, 0.9959596991539001, 0.9995086789131165, 0.9999532103538513, 0.999674379825592, 0.9990384578704834, 0.2831842303276062, 0.7165116667747498, 0.998698353767395, 0.9994350075721741, 0.9997262358665466, 0.999345064163208, 0.21190953254699707, 0.7880607843399048, 0.39826467633247375, 0.036330513656139374, 0.5655221343040466, 0.5964106917381287, 0.4034651815891266, 0.12181179970502853, 0.8781730532646179, 0.9999712109565735, 0.999532163143158, 0.9992082715034485, 0.9991050958633423, 0.9997742176055908, 0.9996122121810913, 0.5255034565925598, 0.031509000808000565, 0.059331852942705154, 0.2796928882598877, 0.09796067327260971, 0.0060089281760156155, 0.9992840886116028, 0.7611856460571289, 0.03573593869805336, 0.0886143296957016, 0.11446298658847809, 0.9990769624710083, 0.0006327276350930333, 0.07428763061761856, 0.07168104499578476, 0.4385233521461487, 0.23692470788955688, 0.1780707985162735, 0.0005487544112838805, 0.9990559220314026, 0.9992930889129639, 0.2928822934627533, 0.11937180906534195, 0.08517897129058838, 0.386851966381073, 0.03467784449458122, 0.08105643093585968, 0.27407106757164, 0.23855505883693695, 0.031562767922878265, 0.3615802824497223, 0.09421391040086746, 0.9990289211273193, 0.9997962713241577, 0.999306321144104, 0.242811918258667, 0.12562353909015656, 0.16454026103019714, 0.20518235862255096, 0.0459003783762455, 0.21594540774822235, 0.3209041655063629, 0.22900794446468353, 0.4500613212585449, 0.9996360540390015, 0.9984481334686279, 0.998830258846283, 0.2827613949775696, 0.7172238826751709, 0.9990732669830322, 0.9993939995765686, 0.13346980512142181, 0.8665270805358887, 0.9995287656784058, 0.9996434450149536, 0.5998479127883911, 0.0005800590151920915, 0.19541294872760773, 0.009437114000320435, 0.19469903409481049, 0.9993413090705872, 0.9994032979011536, 0.15191079676151276, 0.8480632901191711, 0.19946014881134033, 0.05536738783121109, 0.6678476333618164, 0.07726214826107025, 0.1535186469554901, 0.6802235841751099, 0.16620135307312012, 0.9991695284843445, 0.003427727147936821, 0.15906286239624023, 0.6029534935951233, 0.10405600070953369, 0.130498468875885, 0.2431568056344986, 0.26325473189353943, 0.34411829710006714, 0.07850463688373566, 0.07095611840486526, 0.14492708444595337, 0.7232268452644348, 0.06726127862930298, 0.06458811461925507, 0.7478417754173279, 0.25212693214416504, 0.060009732842445374, 0.604991614818573, 0.04068828001618385, 0.13397181034088135, 0.16030597686767578], \"Term\": [\"accept\", \"account\", \"account\", \"acne\", \"acne_solution\", \"address\", \"ago\", \"ago\", \"ago\", \"ago\", \"airport\", \"allergic\", \"always\", \"always\", \"always\", \"always\", \"amount\", \"amount\", \"amount\", \"animal\", \"applicator\", \"appointment\", \"appreciate\", \"ask\", \"ask\", \"assist\", \"assist\", \"associate\", \"attitude\", \"available\", \"available\", \"available\", \"aveda\", \"away\", \"away\", \"back\", \"back\", \"back\", \"back\", \"back\", \"back\", \"bad\", \"bad\", \"bad\", \"be\", \"be\", \"be\", \"be\", \"be\", \"beauty\", \"birthday\", \"black\", \"black\", \"black\", \"black\", \"blend\", \"blush\", \"bobbi_brown\", \"body\", \"body\", \"bonus\", \"book\", \"bother\", \"bottle\", \"bottle\", \"box\", \"brand\", \"brand\", \"break\", \"break\", \"breakout\", \"brown\", \"brush\", \"brush\", \"bumble\", \"bump\", \"burn\", \"busy\", \"buy\", \"buy\", \"buy\", \"call\", \"call\", \"call\", \"calm\", \"cancel\", \"candle\", \"cap\", \"card\", \"carmine\", \"cause\", \"certificate\", \"change\", \"change\", \"change\", \"charge\", \"charge\", \"cheap\", \"check\", \"check\", \"check\", \"check\", \"check\", \"checkout\", \"cheek\", \"chemical\", \"cleanser\", \"clinique\", \"clinique\", \"clinique\", \"clinique\", \"clinique\", \"clinique\", \"close\", \"close\", \"code\", \"collaborate\", \"collaboration\", \"collection\", \"color\", \"colour\", \"come\", \"come\", \"come\", \"come\", \"come\", \"come\", \"come\", \"comment\", \"comment\", \"compact\", \"company\", \"company\", \"complain\", \"concealer\", \"concealer\", \"concealer\", \"conditioner\", \"confirm\", \"consider\", \"consumer\", \"contact\", \"contact\", \"contain\", \"contain\", \"container\", \"corporate\", \"could\", \"could\", \"could\", \"could\", \"counter\", \"coverage\", \"cream\", \"cream\", \"credit\", \"credit\", \"curly\", \"currently\", \"customer\", \"customer\", \"customer\", \"cut\", \"damage\", \"damaged\", \"damaged_insufficient\", \"day\", \"day\", \"day\", \"dermatologist\", \"design\", \"discontinue\", \"discontinued\", \"discount\", \"donation\", \"double\", \"double\", \"dry\", \"dry\", \"early\", \"easy\", \"email\", \"email\", \"email\", \"employee\", \"event\", \"exchange\", \"expensive\", \"expire\", \"eye\", \"eye\", \"eyeliner\", \"eyeliner\", \"eyeshadow\", \"face\", \"fashion\", \"feature\", \"feel\", \"feel\", \"feel\", \"feel\", \"find\", \"find\", \"find\", \"find\", \"find\", \"first\", \"first\", \"first\", \"first\", \"follow\", \"follow\", \"follow\", \"follower\", \"form\", \"formula\", \"formula\", \"foundation\", \"foundation\", \"foundation\", \"fragrance\", \"free\", \"free\", \"free\", \"fresh\", \"friendly\", \"frustrated\", \"full\", \"full\", \"full\", \"full\", \"full\", \"get\", \"get\", \"get\", \"get\", \"gift\", \"girl\", \"girl\", \"give\", \"give\", \"give\", \"give\", \"give\", \"give\", \"gloss\", \"gluten\", \"go\", \"go\", \"go\", \"go\", \"go\", \"good\", \"good\", \"good\", \"good\", \"good\", \"great\", \"great\", \"hair\", \"hairspray\", \"happen\", \"happen\", \"happen\", \"happen\", \"head\", \"head\", \"help\", \"help\", \"help\", \"help\", \"help\", \"help\", \"helpful\", \"home\", \"home\", \"honey\", \"hope\", \"hope\", \"hope\", \"hot\", \"influencer\", \"info\", \"information\", \"information\", \"ingredient\", \"ingredient\", \"ingredient\", \"instagram\", \"interested\", \"irritated\", \"itch\", \"itchy\", \"item\", \"item\", \"item\", \"know\", \"know\", \"know\", \"know\", \"know\", \"know\", \"know\", \"label\", \"label\", \"lady\", \"lady\", \"lash\", \"last\", \"last\", \"last\", \"last\", \"last\", \"later\", \"leak\", \"let\", \"let\", \"let\", \"let\", \"let\", \"light\", \"light\", \"like\", \"liner\", \"liner\", \"lip\", \"lip\", \"lipstick\", \"lipstick\", \"list\", \"list\", \"liter\", \"little\", \"little\", \"little\", \"location\", \"long\", \"long\", \"long\", \"long\", \"long\", \"look\", \"look\", \"love\", \"love\", \"love\", \"macy\", \"mail\", \"mail\", \"make\", \"make\", \"make\", \"make\", \"make\", \"make\", \"makeover\", \"makeup\", \"makeup\", \"makeup\", \"makeup\", \"mall\", \"manager\", \"many\", \"many\", \"many\", \"many\", \"mask\", \"membership\", \"mention\", \"money\", \"money\", \"month\", \"month\", \"month\", \"month\", \"morning\", \"morning\", \"mother\", \"move\", \"name\", \"neck\", \"nee\", \"need\", \"need\", \"need\", \"need\", \"need\", \"need\", \"need\", \"neutral\", \"new\", \"new\", \"new\", \"new\", \"new\", \"new\", \"new\", \"night\", \"normal\", \"notice\", \"notice\", \"notice\", \"notice\", \"number\", \"number\", \"offer\", \"offer\", \"offer\", \"offer\", \"oily\", \"old\", \"old\", \"old\", \"old\", \"old\", \"old\", \"online\", \"open\", \"open\", \"open\", \"opportunity\", \"order\", \"origin\", \"origin\", \"origin\", \"pack\", \"package\", \"package\", \"package\", \"packaging\", \"packaging\", \"page\", \"palette\", \"paraben\", \"partner\", \"peel\", \"pencil\", \"pencil\", \"perfume\", \"perfume\", \"person\", \"person\", \"person\", \"phone\", \"phone\", \"photo\", \"picture\", \"piece\", \"piece\", \"pimple\", \"pink\", \"pink\", \"place\", \"plastic\", \"pm\", \"point\", \"point\", \"policy\", \"poor\", \"post\", \"powder\", \"press\", \"product\", \"product\", \"product\", \"product\", \"product\", \"product\", \"product\", \"production\", \"promo\", \"promote\", \"promotion\", \"promotional\", \"provide\", \"provide\", \"provide\", \"pump\", \"purchase\", \"purchase\", \"purchase\", \"purchase\", \"purchase\", \"pure\", \"put\", \"put\", \"put\", \"put\", \"put\", \"put\", \"quality\", \"quality\", \"quite\", \"quite\", \"rash\", \"reach\", \"reaction\", \"receipt\", \"receive\", \"recently\", \"recently\", \"recently\", \"recently\", \"recently\", \"recently\", \"recycle\", \"red\", \"redness\", \"refuse\", \"remedy\", \"repair\", \"replacement\", \"replacement\", \"replacement\", \"return\", \"return\", \"review\", \"reward\", \"rich\", \"rise\", \"rude\", \"sale\", \"sale\", \"salon\", \"salon\", \"sample\", \"sample\", \"sample\", \"sample\", \"say\", \"say\", \"say\", \"scent\", \"schedule\", \"school\", \"search\", \"search\", \"see\", \"see\", \"see\", \"see\", \"see\", \"see\", \"send\", \"send\", \"send\", \"sensitive\", \"separate\", \"service\", \"shade\", \"shadow\", \"shadow\", \"shampoo\", \"shampoo\", \"shampure\", \"shampure\", \"share\", \"sharpen\", \"shine\", \"ship\", \"shipping\", \"sign\", \"size\", \"size\", \"skin\", \"skin\", \"skincare\", \"smell\", \"solution\", \"sonic\", \"speak\", \"speak\", \"spill\", \"spot\", \"spray\", \"staff\", \"start\", \"start\", \"state\", \"state\", \"state\", \"stock\", \"stock\", \"stop\", \"stop\", \"store\", \"student\", \"stylist\", \"sulfate\", \"super\", \"support\", \"take\", \"take\", \"take\", \"take\", \"take\", \"take\", \"team\", \"tell\", \"tell\", \"tell\", \"tell\", \"terrible\", \"terrible\", \"thank\", \"thank\", \"thank\", \"thank\", \"thank\", \"thank\", \"thick\", \"thin\", \"think\", \"think\", \"think\", \"think\", \"think\", \"think\", \"time\", \"time\", \"time\", \"time\", \"time\", \"tint\", \"top\", \"transfer\", \"try\", \"try\", \"try\", \"try\", \"try\", \"try\", \"tube\", \"tube\", \"tube\", \"twice\", \"ulta\", \"up\", \"use\", \"use\", \"user\", \"video\", \"wait\", \"wait\", \"wake\", \"walk\", \"want\", \"want\", \"want\", \"want\", \"want\", \"wanted\", \"waste\", \"wear\", \"wear\", \"website\", \"website\", \"website\", \"website\", \"week\", \"week\", \"week\", \"wholesale\", \"wonder\", \"wonder\", \"wonder\", \"wonder\", \"wonder\", \"work\", \"work\", \"work\", \"work\", \"work\", \"would\", \"would\", \"would\", \"would\", \"wrong\", \"wrong\", \"year\", \"year\", \"year\", \"year\", \"year\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 6, 5, 3, 7, 2, 4]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el176426386986637522295364953\", ldavis_el176426386986637522295364953_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el176426386986637522295364953\", ldavis_el176426386986637522295364953_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el176426386986637522295364953\", ldavis_el176426386986637522295364953_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "0      0.150048 -0.118787       1        1  20.012102\n",
       "5      0.070020  0.069810       2        1  15.807926\n",
       "4      0.024586  0.043639       3        1  15.266879\n",
       "2      0.132043 -0.036537       4        1  14.823845\n",
       "6     -0.003691  0.333769       5        1  13.913451\n",
       "1      0.049273 -0.223394       6        1  12.986086\n",
       "3     -0.422279 -0.068500       7        1   7.189713, topic_info=         Term          Freq         Total Category  logprob  loglift\n",
       "28       look  62265.000000  62265.000000  Default  30.0000  30.0000\n",
       "135     order  43954.000000  43954.000000  Default  29.0000  29.0000\n",
       "64        use  61673.000000  61673.000000  Default  28.0000  28.0000\n",
       "22      color  40396.000000  40396.000000  Default  27.0000  27.0000\n",
       "75      store  43833.000000  43833.000000  Default  26.0000  26.0000\n",
       "...       ...           ...           ...      ...      ...      ...\n",
       "222      come   2690.496582  17067.542969   Topic7  -4.8142   0.7851\n",
       "1140    state   1649.718384   2917.657715   Topic7  -5.3034   2.0623\n",
       "302   package   1794.194458   5315.109375   Topic7  -5.2194   1.5465\n",
       "411    pencil   1659.189697   6747.393555   Topic7  -5.2976   1.2297\n",
       "14       back   1501.735229  27127.966797   Topic7  -5.3973  -0.2614\n",
       "\n",
       "[446 rows x 6 columns], token_table=      Topic      Freq           Term\n",
       "term                                \n",
       "2047      7  0.999481         accept\n",
       "370       3  0.308106        account\n",
       "370       6  0.691726        account\n",
       "549       4  0.999267           acne\n",
       "806       5  0.998834  acne_solution\n",
       "...     ...       ...            ...\n",
       "66        1  0.060010           year\n",
       "66        2  0.604992           year\n",
       "66        3  0.040688           year\n",
       "66        4  0.133972           year\n",
       "66        5  0.160306           year\n",
       "\n",
       "[684 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[1, 6, 5, 3, 7, 2, 4])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "LDAvis_prepared = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n",
    "LDAvis_prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
